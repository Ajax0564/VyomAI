{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T07:42:47.345766Z","iopub.status.busy":"2024-04-29T07:42:47.344720Z","iopub.status.idle":"2024-04-29T07:42:47.773589Z","shell.execute_reply":"2024-04-29T07:42:47.772581Z","shell.execute_reply.started":"2024-04-29T07:42:47.345731Z"},"trusted":true},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"markdown","metadata":{},"source":["**Data used**\n","\n","\n","[https://www.kaggle.com/datasets/ajax0564/quotes-dataset](http://)"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T07:42:47.775873Z","iopub.status.busy":"2024-04-29T07:42:47.775359Z","iopub.status.idle":"2024-04-29T07:42:50.804240Z","shell.execute_reply":"2024-04-29T07:42:50.803430Z","shell.execute_reply.started":"2024-04-29T07:42:47.775837Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv(\"../input/transformer-dataprep/All_Quotes.csv\")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T07:42:50.805632Z","iopub.status.busy":"2024-04-29T07:42:50.805293Z","iopub.status.idle":"2024-04-29T07:42:50.812574Z","shell.execute_reply":"2024-04-29T07:42:50.811741Z","shell.execute_reply.started":"2024-04-29T07:42:50.805603Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(526110, 3)"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T07:42:50.815549Z","iopub.status.busy":"2024-04-29T07:42:50.815234Z","iopub.status.idle":"2024-04-29T07:42:50.836623Z","shell.execute_reply":"2024-04-29T07:42:50.835649Z","shell.execute_reply.started":"2024-04-29T07:42:50.815520Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>quote</th>\n","      <th>index</th>\n","      <th>text_length</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>If you do not take an interest in the affairs ...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A wise man speaks because he has something to ...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Someday, in the distant future, our grand-chil...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               quote  index  text_length\n","0  If you do not take an interest in the affairs ...    NaN          NaN\n","1  A wise man speaks because he has something to ...    NaN          NaN\n","2  Someday, in the distant future, our grand-chil...    NaN          NaN"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df.head(3)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T07:42:50.837825Z","iopub.status.busy":"2024-04-29T07:42:50.837541Z","iopub.status.idle":"2024-04-29T07:42:52.417737Z","shell.execute_reply":"2024-04-29T07:42:52.416813Z","shell.execute_reply.started":"2024-04-29T07:42:50.837777Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Maximum text length: 5459\n","Minimum text length: 1\n"]}],"source":["df[\"quote_length\"] = df[\"quote\"].apply(lambda x: len(x.split()))\n","\n","# Get the maximum and minimum text lengths\n","max_text_length = df[\"quote_length\"].max()\n","min_text_length = df[\"quote_length\"].min()\n","\n","# Print the results\n","print(\"Maximum text length:\", max_text_length)\n","print(\"Minimum text length:\", min_text_length)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T07:42:52.419445Z","iopub.status.busy":"2024-04-29T07:42:52.419089Z","iopub.status.idle":"2024-04-29T07:42:52.504512Z","shell.execute_reply":"2024-04-29T07:42:52.501128Z","shell.execute_reply.started":"2024-04-29T07:42:52.419414Z"},"trusted":true},"outputs":[],"source":["dff = df[df[\"quote_length\"] >= 5].reset_index(drop=True)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T07:42:52.506409Z","iopub.status.busy":"2024-04-29T07:42:52.506015Z","iopub.status.idle":"2024-04-29T07:42:52.525413Z","shell.execute_reply":"2024-04-29T07:42:52.524181Z","shell.execute_reply.started":"2024-04-29T07:42:52.506370Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>quote</th>\n","      <th>index</th>\n","      <th>text_length</th>\n","      <th>quote_length</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>46900</th>\n","      <td>Self-talk reflects your innermost feelings.</td>\n","      <td>1789.0</td>\n","      <td>43.0</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>47247</th>\n","      <td>Sometimes, remembering hurts too much.</td>\n","      <td>2145.0</td>\n","      <td>38.0</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>47530</th>\n","      <td>Because...because...she came here with me.</td>\n","      <td>2438.0</td>\n","      <td>42.0</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>48532</th>\n","      <td>Cynics are simply thwarted romantics.</td>\n","      <td>3471.0</td>\n","      <td>37.0</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>49073</th>\n","      <td>Forget injuries, never forget kindnesses.</td>\n","      <td>4032.0</td>\n","      <td>41.0</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>517685</th>\n","      <td>Every relationship has its complications.</td>\n","      <td>491243.0</td>\n","      <td>41.0</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>518209</th>\n","      <td>Success demands singleness of purpose.</td>\n","      <td>491783.0</td>\n","      <td>38.0</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>519378</th>\n","      <td>Men aren't necessities. They're luxuries.</td>\n","      <td>492984.0</td>\n","      <td>41.0</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>519663</th>\n","      <td>Getting angry doesn't solve anything.</td>\n","      <td>493277.0</td>\n","      <td>37.0</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>520259</th>\n","      <td>Exercise is labor without weariness.</td>\n","      <td>493891.0</td>\n","      <td>36.0</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>899 rows × 4 columns</p>\n","</div>"],"text/plain":["                                              quote     index  text_length  \\\n","46900   Self-talk reflects your innermost feelings.    1789.0         43.0   \n","47247        Sometimes, remembering hurts too much.    2145.0         38.0   \n","47530    Because...because...she came here with me.    2438.0         42.0   \n","48532         Cynics are simply thwarted romantics.    3471.0         37.0   \n","49073     Forget injuries, never forget kindnesses.    4032.0         41.0   \n","...                                             ...       ...          ...   \n","517685    Every relationship has its complications.  491243.0         41.0   \n","518209       Success demands singleness of purpose.  491783.0         38.0   \n","519378    Men aren't necessities. They're luxuries.  492984.0         41.0   \n","519663        Getting angry doesn't solve anything.  493277.0         37.0   \n","520259         Exercise is labor without weariness.  493891.0         36.0   \n","\n","        quote_length  \n","46900              5  \n","47247              5  \n","47530              5  \n","48532              5  \n","49073              5  \n","...              ...  \n","517685             5  \n","518209             5  \n","519378             5  \n","519663             5  \n","520259             5  \n","\n","[899 rows x 4 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["dff[dff[\"quote_length\"] == 5]"]},{"cell_type":"markdown","metadata":{},"source":["**Reading Material to understand MLM**\n","\n","\n","https://web.stanford.edu/~jurafsky/slp3/11.pdf](http://)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T07:42:52.527018Z","iopub.status.busy":"2024-04-29T07:42:52.526580Z","iopub.status.idle":"2024-04-29T07:42:58.175878Z","shell.execute_reply":"2024-04-29T07:42:58.174851Z","shell.execute_reply.started":"2024-04-29T07:42:52.526985Z"},"trusted":true},"outputs":[],"source":["import os\n","from torch.cuda.amp import GradScaler, autocast\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import (\n","    AutoModel,\n","    AutoTokenizer,\n","    AdamW,\n","    get_linear_schedule_with_warmup,\n",")\n","import gc\n","import numpy as np\n","from transformers import AutoConfig\n","from tqdm.notebook import tqdm\n","\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n","import warnings\n","\n","warnings.simplefilter(\"ignore\")"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T07:42:58.177507Z","iopub.status.busy":"2024-04-29T07:42:58.177099Z","iopub.status.idle":"2024-04-29T07:42:59.090752Z","shell.execute_reply":"2024-04-29T07:42:59.089735Z","shell.execute_reply.started":"2024-04-29T07:42:58.177481Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7333e43aae6d4e4a80e364c16064a139","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"47ca2c1603974a6c8a41e9b263154353","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d25e37bd66bc4088bffb1fd6cc4796c5","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"62d913ad8fd343588b6d68f77abe7c30","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b736ee393c714a94aac931720758c7bc","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["model_ckpt = \"roberta-base\"\n","tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T07:42:59.095422Z","iopub.status.busy":"2024-04-29T07:42:59.095123Z","iopub.status.idle":"2024-04-29T07:42:59.104245Z","shell.execute_reply":"2024-04-29T07:42:59.103319Z","shell.execute_reply.started":"2024-04-29T07:42:59.095397Z"},"trusted":true},"outputs":[],"source":["import torch\n","\n","\n","class MLMDataset(Dataset):\n","    def __init__(self, text):\n","        self.text = text\n","        self.max_len = 128\n","        self.tokenizer = tokenizer\n","        self.num_examples = len(self.text)\n","\n","    def __len__(self):\n","        return self.num_examples\n","\n","    def __getitem__(self, idx):\n","        text = str(self.text[idx])\n","\n","        tokenized_text = self.tokenizer(\n","            text,\n","            add_special_tokens=True,\n","            truncation=True,\n","            padding=\"max_length\",\n","            max_length=self.max_len,\n","            return_attention_mask=True,\n","        )\n","\n","        ids = tokenized_text[\"input_ids\"]\n","        mask = tokenized_text[\"attention_mask\"]\n","\n","        return {\n","            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n","            \"attention_mask\": torch.tensor(mask, dtype=torch.long),\n","        }"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T07:42:59.105908Z","iopub.status.busy":"2024-04-29T07:42:59.105538Z","iopub.status.idle":"2024-04-29T07:42:59.119584Z","shell.execute_reply":"2024-04-29T07:42:59.118562Z","shell.execute_reply.started":"2024-04-29T07:42:59.105877Z"},"trusted":true},"outputs":[],"source":["import torch\n","from typing import Optional, Tuple\n","\n","\n","def masked_language_modeling(\n","    input_ids: torch.Tensor,\n","    tokenizer=tokenizer,\n","    fraction: float = 0.15,\n","    ignore_index: int = -100,\n",") -> Tuple[torch.Tensor]:\n","    label = input_ids.clone()\n","\n","    special_tokens_mask = torch.tensor(\n","        [\n","            tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True)\n","            for val in label.tolist()\n","        ],\n","        dtype=torch.bool,\n","    )  # get all special token mask to ignore their selection in MLM\n","    probability_matrix = torch.full(\n","        label.shape, fraction\n","    )  # gen probability matrix to select 15% tokens for MLM\n","    probability_matrix.masked_fill_(\n","        special_tokens_mask, value=0.0\n","    )  # zero out the probability of special tokens so that they do not get selected\n","    # https://pytorch.org/docs/stable/generated/torch.bernoulli.html\n","    # Draws binary random numbers (0 or 1) from a Bernoulli distribution.\n","    masked_indices = torch.bernoulli(probability_matrix).bool()\n","\n","    label[~masked_indices] = (\n","        ignore_index  # We only compute loss on masked tokens cross entropy ignore_index\n","    )\n","\n","    # 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\n","    indices_replaced = (\n","        torch.bernoulli(torch.full(label.shape, 0.8)).bool() & masked_indices\n","    )  # rondomly select 80% tokens from 15% token\n","    input_ids[indices_replaced] = tokenizer.convert_tokens_to_ids(\n","        tokenizer.mask_token\n","    )  # replace it with [MASK]\n","\n","    # 10% of the time, we replace masked input tokens with random word\n","    indices_random = (\n","        torch.bernoulli(torch.full(label.shape, 0.5)).bool()\n","        & masked_indices\n","        & ~indices_replaced\n","    )  # from 15% ignore 80% select 10% from 20%\n","    random_words = torch.randint(\n","        len(tokenizer), label.shape, dtype=torch.long\n","    )  # get random token index from tokenizer\n","    input_ids[indices_random] = random_words[indices_random]\n","\n","    # The rest of the time (10% of the time) we keep the masked input tokens unchanged do nothing\n","    #     batch['input_ids_modified'] = input_ids\n","    #     batch['label'] = label\n","    #     batch['masked_indices'] = masked_indices\n","    return input_ids, label, masked_indices"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T07:42:59.121260Z","iopub.status.busy":"2024-04-29T07:42:59.120663Z","iopub.status.idle":"2024-04-29T07:43:12.641415Z","shell.execute_reply":"2024-04-29T07:43:12.640281Z","shell.execute_reply.started":"2024-04-29T07:42:59.121227Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting einops\n","  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n","Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: einops\n","Successfully installed einops-0.8.0\n"]}],"source":["!pip install einops"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T07:43:12.643589Z","iopub.status.busy":"2024-04-29T07:43:12.643300Z","iopub.status.idle":"2024-04-29T07:43:12.675195Z","shell.execute_reply":"2024-04-29T07:43:12.674366Z","shell.execute_reply.started":"2024-04-29T07:43:12.643562Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from einops import rearrange, reduce\n","from typing import Optional, Tuple\n","\n","\n","class AbsoluteEncoding(nn.Module):\n","    def __init__(self, config) -> None:\n","        super().__init__()\n","        self.pos_embeddings = nn.Embedding(\n","            config.max_position_embeddings, config.hidden_size\n","        )\n","        self.register_buffer(\n","            \"position_ids\",\n","            torch.arange(config.max_position_embeddings).expand((1, -1)),\n","            persistent=False,\n","        )\n","        self.max_size = config.max_position_embeddings\n","\n","    def forward(self, size: int) -> torch.Tensor:\n","        if self.max_size < size:\n","            raise ValueError(\n","                f\"The hidden size ({size }) is more than the config max_position_embeddings {self.max_size}\"\n","            )\n","        return self.pos_embeddings(self.position_ids[:, :size])\n","\n","\n","class SinusoidalEncoding(nn.Module):\n","    def __init__(self, config) -> None:\n","        super().__init__()\n","        if config.hidden_size % 2 != 0:\n","            raise ValueError(\n","                f\"Cannot use SinusoidalEncoding with \"\n","                \"odd hidden dim got dim {config.hidden_size}\"\n","            )\n","        self.positional_encoding = torch.zeros(\n","            1, config.max_position_embeddings, config.hidden_size\n","        )\n","        self.position = torch.arange(0, config.max_position_embeddings).unsqueeze(1)\n","        self.div_term = torch.exp(\n","            (\n","                torch.arange(0, config.hidden_size, 2, dtype=torch.float)\n","                * -(torch.log(torch.tensor(10000.0)) / config.hidden_size)\n","            )\n","        )\n","\n","        self.positional_encoding[:, :, 0::2] = torch.sin(\n","            self.position.float() * self.div_term\n","        )\n","        self.positional_encoding[:, :, 1::2] = torch.cos(\n","            self.position.float() * self.div_term\n","        )\n","\n","    def forward(self, seq_len: int) -> torch.Tensor:\n","\n","        return self.positional_encoding[:, :seq_len]\n","\n","\n","# copied from transformer/models/gemma\n","class RotaryEmbedding(nn.Module):\n","    def __init__(self, config, base=10000, device=None):\n","        super().__init__()\n","\n","        self.dim = int(config.hidden_size // config.num_attention_heads)\n","        self.max_position_embeddings = config.max_position_embeddings\n","        self.base = base\n","        self.register_buffer(\n","            \"inv_freq\",\n","            1.0\n","            / (\n","                self.base\n","                ** (torch.arange(0, self.dim, 2, dtype=torch.int64).float() / self.dim)\n","            ),\n","            persistent=False,\n","        )\n","        self.register_buffer(\n","            \"position_ids\",\n","            torch.arange(config.max_position_embeddings).expand((1, -1)),\n","            persistent=False,\n","        )\n","\n","    @torch.no_grad()\n","    def forward(self, seq_len: int = None):\n","        # x: [bs, num_attention_heads, seq_len, head_size]\n","        # size = x.size()[2]\n","        position_ids = torch.arange(seq_len).unsqueeze(0)\n","        # position_ids = self.position_ids[:, :size].float()\n","\n","        inv_freq_expanded = (\n","            self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n","        )\n","        position_ids_expanded = position_ids[:, None, :].float()\n","\n","        freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(\n","            1, 2\n","        )\n","        return freqs\n","\n","\n","# Copied from transformers.models.llama.modeling_llama.rotate_half\n","def rotate_half(x):\n","    \"\"\"Rotates half the hidden dims of the input.\"\"\"\n","    x1 = x[..., : x.shape[-1] // 2]\n","    x2 = x[..., x.shape[-1] // 2 :]\n","    return torch.cat((-x2, x1), dim=-1)\n","\n","\n","# def rotate_half(x):\n","#     x1, x2 = x.chunk(2, dim=-1)\n","#     return torch.cat((-x2, x1), dim=-1)\n","\n","\n","# Copied from transformers.models.llama.modeling_llama.apply_rotary_pos_emb\n","def apply_rotary_pos_emb(\n","    q, k, freqs, only_q: bool = False, unsqueeze_dim=1\n",") -> Tuple[torch.Tensor]:\n","    \"\"\"Applies Rotary Position Embedding to the query and key tensors.\n","\n","    Args:\n","        q (`torch.Tensor`): The query tensor.\n","        k (`torch.Tensor`): The key tensor.\n","        freqs: precalculated frqs for sin cos\n","        only_q: bool = False for encoder decoder\n","        unsqueeze_dim (`int`, *optional*, defaults to 1):\n","            The 'unsqueeze_dim' argument specifies the dimension along which to unsqueeze cos[position_ids] and\n","            sin[position_ids] so that they can be properly broadcasted to the dimensions of q and k. For example, note\n","            that cos[position_ids] and sin[position_ids] have the shape [batch_size, seq_len, head_dim]. Then, if q and\n","            k have the shape [batch_size, heads, seq_len, head_dim], then setting unsqueeze_dim=1 makes\n","            cos[position_ids] and sin[position_ids] broadcastable to the shapes of q and k. Similarly, if q and k have\n","            the shape [batch_size, seq_len, heads, head_dim], then set unsqueeze_dim=2.\n","    Returns:\n","        `tuple(torch.Tensor)` comprising of the query and key tensors rotated using the Rotary Position Embedding.\n","    \"\"\"\n","    emb = torch.cat((freqs, freqs), dim=-1)\n","    cos = emb.cos()\n","    sin = emb.sin()\n","    cos = cos.unsqueeze(unsqueeze_dim)\n","    sin = sin.unsqueeze(unsqueeze_dim)\n","    #     print(cos.size(),sin.size(),q.size(),k.size())\n","    if only_q:\n","        q_embed = (q * cos) + (rotate_half(q) * sin)\n","    else:\n","\n","        q_embed = (q * cos) + (rotate_half(q) * sin)\n","        k_embed = (k * cos) + (rotate_half(k) * sin)\n","        return q_embed, k_embed"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T07:43:12.676680Z","iopub.status.busy":"2024-04-29T07:43:12.676385Z","iopub.status.idle":"2024-04-29T07:43:12.689389Z","shell.execute_reply":"2024-04-29T07:43:12.688578Z","shell.execute_reply.started":"2024-04-29T07:43:12.676657Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from einops import rearrange, reduce\n","from typing import Optional, Tuple, Union\n","\n","_ACT_ = {\n","    \"gelu\": nn.GELU(),\n","    \"leaky_relu\": nn.LeakyReLU(),\n","    \"relu6\": nn.ReLU6(),\n","    \"sigmoid\": nn.Sigmoid(),\n","    \"silu\": nn.SiLU(),\n","    \"swish\": nn.SiLU(),\n","    \"tanh\": nn.Tanh(),\n","}\n","\n","\n","class FeedForward(nn.Module):\n","    def __init__(self, config, multiplier: Union[int, float] = 4) -> None:\n","        super().__init__()\n","        self.intermediate = nn.Linear(\n","            config.hidden_size, int(multiplier) * config.hidden_size\n","        )\n","        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n","        self.layerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n","        if _ACT_.get(getattr(config, \"hidden_act\", None), None):\n","            self.act_fn = _ACT_[config.hidden_act]\n","        else:\n","            self.act_fn = nn.GELU()\n","        self.out = nn.Linear(int(multiplier) * config.hidden_size, config.hidden_size)\n","\n","    def forward(\n","        self, hidden_state: torch.Tensor, input_tensor: torch.Tensor\n","    ) -> torch.Tensor:\n","        output = self.intermediate(hidden_state)\n","        output = self.act_fn(output)\n","        output = self.out(output)\n","        output = self.dropout(output)\n","        output = self.layerNorm(output + input_tensor)\n","        return output"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T07:43:12.691409Z","iopub.status.busy":"2024-04-29T07:43:12.690868Z","iopub.status.idle":"2024-04-29T07:43:12.718998Z","shell.execute_reply":"2024-04-29T07:43:12.717954Z","shell.execute_reply.started":"2024-04-29T07:43:12.691375Z"},"trusted":true},"outputs":[],"source":["def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n","    \"\"\"\n","    This is the equivalent of torch.repeat_interleave(x, dim=1, repeats=n_rep). The hidden states go from (batch,\n","    num_key_value_heads, seqlen, head_dim) to (batch, num_attention_heads, seqlen, head_dim)\n","    \"\"\"\n","    batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n","    if n_rep == 1:\n","        return hidden_states\n","    hidden_states = hidden_states[:, :, None, :, :].expand(\n","        batch, num_key_value_heads, n_rep, slen, head_dim\n","    )\n","    return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n","\n","\n","def repeat_kv_einops(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n","    \"\"\"\n","    This is the equivalent of torch.repeat_interleave(x, dim=1, repeats=n_rep). The hidden states go from (batch,\n","    num_key_value_heads, seqlen, head_dim) to (batch, num_attention_heads, seqlen, head_dim)\n","    \"\"\"\n","    batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n","    if n_rep == 1:\n","        return hidden_states\n","    hidden_states = repeat(\n","        hidden_states,\n","        \"batch num_key_value_heads slen head_dim -> batch num_key_value_heads n_rep slen head_dim\",\n","        n_rep=n_rep,\n","    )  # hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n","    # return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n","    return rearrange(\n","        hidden_states,\n","        \"batch num_key_value_heads n_rep slen head_dim -> batch (num_key_value_heads n_rep) slen head_dim\",\n","    )\n","\n","\n","class EncoderAttention(nn.Module):\n","    def __init__(self, config, layer_idx: int) -> None:\n","        super().__init__()\n","        if config.hidden_size % config.num_attention_heads != 0:\n","            raise ValueError(\n","                f\"The hidden size ({config.hidden_size}) is not a multiple of the number of attention \"\n","                f\"heads ({config.num_attention_heads})\"\n","            )\n","        self.head_size = int(config.hidden_size // config.num_attention_heads)\n","        self.attention_bias = getattr(config, \"attention_bias\", True)\n","        self.layer_idx = layer_idx\n","        # self.qkv = nn.Linear(config.hidden_size,3*config.hidden_size)\n","        self.q = nn.Linear(\n","            config.hidden_size, config.hidden_size, bias=self.attention_bias\n","        )\n","        self.k = nn.Linear(\n","            config.hidden_size, config.hidden_size, bias=self.attention_bias\n","        )\n","        self.v = nn.Linear(\n","            config.hidden_size, config.hidden_size, bias=self.attention_bias\n","        )\n","        self.out = nn.Linear(\n","            config.hidden_size, config.hidden_size, bias=self.attention_bias\n","        )\n","        self.num_attention_heads = config.num_attention_heads\n","\n","    def forward(\n","        self,\n","        hidden_state: torch.Tensor,\n","        attention_mask: torch.Tensor,\n","        freqs: Optional[torch.Tensor] = None,\n","    ) -> torch.Tensor:\n","        q = self.q(hidden_state)\n","        k = self.k(hidden_state)\n","        v = self.v(hidden_state)\n","        # q,k,v = self.qkv(hidden_state).chunk(3, dim = -1) #b X l X d dim =-1 or 2\n","        # place holder for RoPe operation\n","        q = rearrange(q, \"b l (h d) -> b h l d\", h=self.num_attention_heads)\n","        k = rearrange(k, \"b l (h d) -> b h l d\", h=self.num_attention_heads)\n","        v = rearrange(v, \"b l (h d) -> b h l d\", h=self.num_attention_heads)\n","        if freqs is not None:\n","            q, k = apply_rotary_pos_emb(q, k, freqs)\n","\n","        out = torch.nn.functional.scaled_dot_product_attention(\n","            query=q, key=k, value=v, attn_mask=attention_mask, is_causal=False\n","        )\n","        out = rearrange(out, \"b h l d -> b l (h d)\")\n","        out = self.out(out)\n","        return out\n","\n","\n","class EncoderAttentionGqa(nn.Module):\n","    def __init__(self, config, layer_idx: int) -> None:\n","        super().__init__()\n","        if config.hidden_size % config.num_attention_heads != 0:\n","            raise ValueError(\n","                f\"The hidden size ({config.hidden_size}) is not a multiple of the number of attention \"\n","                f\"heads ({config.num_attention_heads})\"\n","            )\n","        self.flash = hasattr(torch.nn.functional, \"scaled_dot_product_attention\")\n","        if not self.flash and self.layer_idx == 0:  # avoid to print m times\n","            print(\"WARNING: Flash Attention requires PyTorch >= 2.0\")\n","        self.layer_idx = layer_idx\n","        self.head_dim = int(config.hidden_size // config.num_attention_heads)\n","        self.num_attention_heads = config.num_attention_heads\n","        self.num_key_value_heads = getattr(config, \"num_key_value_heads\", 4)\n","        self.num_key_value_groups = self.num_attention_heads // self.num_key_value_heads\n","        if (\n","            self.num_attention_heads % self.num_key_value_heads != 0\n","            or self.num_attention_heads < self.num_key_value_heads\n","        ):\n","            raise ValueError(\n","                f\"num_key_value_heads {self.num_key_value_heads }  should be less than equal num_attention_heads {config.num_attention_heads} and  multiple of num_attention_heads {config.num_attention_heads} \"\n","            )\n","        self.attention_bias = getattr(config, \"attention_bias\", True)\n","        self.out = nn.Linear(\n","            config.hidden_size, config.hidden_size, bias=self.attention_bias\n","        )\n","        self.q = nn.Linear(\n","            config.hidden_size, config.hidden_size, bias=self.attention_bias\n","        )\n","        self.k = nn.Linear(\n","            config.hidden_size,\n","            self.num_key_value_heads * self.head_dim,\n","            bias=self.attention_bias,\n","        )\n","        self.v = nn.Linear(\n","            config.hidden_size,\n","            self.num_key_value_heads * self.head_dim,\n","            bias=self.attention_bias,\n","        )\n","\n","    def forward(\n","        self,\n","        hidden_state: torch.Tensor,\n","        attention_mask: torch.Tensor,\n","        freqs: Optional[torch.Tensor] = None,\n","    ) -> torch.Tensor:\n","        q = self.q(hidden_state)\n","        k = self.k(hidden_state)\n","        v = self.v(hidden_state)\n","        q = rearrange(q, \"b l (h d) -> b h l d\", d=self.head_dim)\n","        k = rearrange(k, \"b l (h d) -> b h l d\", d=self.head_dim)\n","        v = rearrange(v, \"b l (h d) -> b h l d\", d=self.head_dim)\n","\n","        if freqs is not None:\n","            q, k = apply_rotary_pos_emb(q, k, freqs)\n","\n","        k = repeat_kv(k, n_rep=self.num_key_value_groups)\n","        v = repeat_kv(v, n_rep=self.num_key_value_groups)\n","        out = torch.nn.functional.scaled_dot_product_attention(\n","            query=q, key=k, value=v, attn_mask=attention_mask, is_causal=False\n","        )\n","        out = rearrange(out, \"b h l d -> b l (h d)\")\n","        out = self.out(out)\n","        return out"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T07:43:12.720460Z","iopub.status.busy":"2024-04-29T07:43:12.720154Z","iopub.status.idle":"2024-04-29T07:43:12.747338Z","shell.execute_reply":"2024-04-29T07:43:12.746335Z","shell.execute_reply.started":"2024-04-29T07:43:12.720432Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from typing import Optional, Tuple\n","from dataclasses import dataclass\n","\n","_position_embeddings = {\n","    \"absolute\": AbsoluteEncoding,\n","    \"sinusoidal\": SinusoidalEncoding,\n","}  #'relative':RelativePositionalEncoding\n","\n","\n","@dataclass\n","class EncoderOutput(object):\n","    logits: torch.Tensor\n","\n","\n","@dataclass\n","class MLMOutput(object):\n","    hidden_state: torch.Tensor\n","    logits: torch.Tensor\n","\n","\n","class EncoderLayer(nn.Module):\n","    def __init__(self, config, layer_idx: int, attention_type: str = None) -> None:\n","        super().__init__()\n","        self.attention = (\n","            EncoderAttentionGqa(config, layer_idx=layer_idx)\n","            if attention_type == \"gqa\"\n","            else EncoderAttention(config, layer_idx=layer_idx)\n","        )\n","        if attention_type == \"gqa\" and layer_idx == 0:  # avoid to print m times\n","            print(\"Encoder Using GQA Attention\")\n","        self.feed_forward = FeedForward(config)\n","        self.layer_idx = layer_idx\n","\n","    def forward(\n","        self,\n","        hidden_state: torch.Tensor,\n","        attention_mask: torch.Tensor,\n","        freqs: torch.Tensor = None,\n","    ) -> torch.Tensor:\n","        out = self.attention(\n","            hidden_state=hidden_state, attention_mask=attention_mask, freqs=freqs\n","        )\n","        out = self.feed_forward(out, hidden_state)\n","        return out\n","\n","\n","class LMHead(nn.Module):\n","    \"\"\"Head for masked language modelling\"\"\"\n","\n","    def __init__(self, config) -> None:\n","        super().__init__()\n","        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n","        self.layer_norm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n","\n","        self.decoder = nn.Linear(config.hidden_size, config.vocab_size)\n","        self.bias = nn.Parameter(torch.zeros(config.vocab_size))\n","        self.decoder.bias = self.bias\n","\n","    def forward(self, hidden_state: torch.Tensor) -> torch.Tensor:\n","        x = self.dense(hidden_state)\n","        x = nn.GELU()(x)\n","        x = self.layer_norm(x)\n","\n","        # project back to size of vocabulary with bias\n","        x = self.decoder(x)\n","\n","        return x\n","\n","\n","class EncoderModel(nn.Module):\n","\n","    def __init__(\n","        self,\n","        config,\n","        pos_embedding_type: Optional[str] = \"absolute\",\n","        attention_type: str = None,\n","    ) -> None:\n","        super().__init__()\n","        self.word_embeddings = nn.Embedding(\n","            config.vocab_size,\n","            config.hidden_size,\n","            padding_idx=getattr(config, \"pad_token_id\", None),\n","        )\n","        if _position_embeddings.get(pos_embedding_type, None) is not None:\n","            self.position_embeddings = _position_embeddings.get(pos_embedding_type)(\n","                config\n","            )\n","        else:\n","            self.position_embeddings = None\n","        if pos_embedding_type == \"rope\":\n","            self.emb_freq = RotaryEmbedding(config)(config.max_position_embeddings)\n","            print(\n","                \"Encoder Ignoring sinusoidal or absolute position embeddings because rope,is enable\"\n","            )\n","        self.all_layer = nn.ModuleList(\n","            [\n","                EncoderLayer(config, layer_idx, attention_type)\n","                for layer_idx in range(config.num_hidden_layers)\n","            ]\n","        )\n","\n","    def forward(\n","        self, input_ids: torch.Tensor, attention_mask: torch.Tensor\n","    ) -> torch.Tensor:\n","        bsz, seqlen = input_ids.shape\n","        hidden_state = self.word_embeddings(input_ids)\n","        freqs = None\n","        if self.position_embeddings is not None:\n","            pos_info = self.position_embeddings(seqlen)[:, :seqlen, :].to(\n","                input_ids.device\n","            )\n","            hidden_state = hidden_state + pos_info\n","        else:\n","            freqs = self.emb_freq[:, :seqlen].to(input_ids.device)\n","\n","        attention_mask = attention_mask.unsqueeze(1).unsqueeze(2).type_as(hidden_state)\n","        attention_mask = (1.0 - attention_mask) * torch.finfo(hidden_state.dtype).min\n","\n","        for layer in self.all_layer:\n","            hidden_state = layer(hidden_state, attention_mask, freqs)\n","        return EncoderOutput(hidden_state)\n","\n","    @classmethod\n","    def from_config(\n","        cls,\n","        config,\n","        pos_embedding_type: Optional[str] = \"absolute\",\n","        attention_type: str = None,\n","    ) -> nn.Module:\n","        return cls(config, pos_embedding_type, attention_type)\n","\n","\n","class EncoderForMaskedLM(nn.Module):\n","\n","    def __init__(\n","        self,\n","        config,\n","        pos_embedding_type: Optional[str] = \"absolute\",\n","        attention_type: str = None,\n","    ) -> None:\n","        super().__init__()\n","        self.encoder = EncoderModel(\n","            config, pos_embedding_type=pos_embedding_type, attention_type=attention_type\n","        )\n","        self.lm_head = LMHead(config=config)\n","\n","    def forward(\n","        self, input_ids: torch.Tensor, attention_mask: torch.Tensor\n","    ) -> torch.Tensor:\n","        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n","        logits = self.lm_head(out.logits)\n","        return MLMOutput(hidden_state=out.logits, logits=logits)\n","\n","    @classmethod\n","    def from_config(\n","        cls,\n","        config,\n","        pos_embedding_type: Optional[str] = \"absolute\",\n","        attention_type: str = None,\n","    ) -> nn.Module:\n","        return cls(config, pos_embedding_type, attention_type)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T07:43:12.749035Z","iopub.status.busy":"2024-04-29T07:43:12.748624Z","iopub.status.idle":"2024-04-29T07:43:12.806197Z","shell.execute_reply":"2024-04-29T07:43:12.805438Z","shell.execute_reply.started":"2024-04-29T07:43:12.749003Z"},"trusted":true},"outputs":[],"source":["config = AutoConfig.from_pretrained(model_ckpt)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T07:43:12.807489Z","iopub.status.busy":"2024-04-29T07:43:12.807212Z","iopub.status.idle":"2024-04-29T07:43:14.101673Z","shell.execute_reply":"2024-04-29T07:43:14.100733Z","shell.execute_reply.started":"2024-04-29T07:43:12.807466Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Encoder Ignoring sinusoidal or absolute position embeddings because rope,is enable\n"]}],"source":["config.num_hidden_layers = 6\n","model = EncoderForMaskedLM(config, pos_embedding_type=\"rope\")"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T07:43:14.103089Z","iopub.status.busy":"2024-04-29T07:43:14.102823Z","iopub.status.idle":"2024-04-29T07:43:18.736592Z","shell.execute_reply":"2024-04-29T07:43:18.735827Z","shell.execute_reply.started":"2024-04-29T07:43:14.103066Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e7a65fac1724c0090af4c612dd53756","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["m = AutoModel.from_pretrained(model_ckpt)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T07:43:18.738196Z","iopub.status.busy":"2024-04-29T07:43:18.737748Z","iopub.status.idle":"2024-04-29T07:43:18.742618Z","shell.execute_reply":"2024-04-29T07:43:18.741534Z","shell.execute_reply.started":"2024-04-29T07:43:18.738169Z"},"trusted":true},"outputs":[],"source":["# print(model.encoder.word_embeddings.weight.size(),model.encoder.position_embeddings.pos_embeddings.weight.size())"]},{"cell_type":"markdown","metadata":{},"source":["**Copy Embeddings for faster convergence**"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T07:43:18.744038Z","iopub.status.busy":"2024-04-29T07:43:18.743780Z","iopub.status.idle":"2024-04-29T07:43:18.764004Z","shell.execute_reply":"2024-04-29T07:43:18.763189Z","shell.execute_reply.started":"2024-04-29T07:43:18.744016Z"},"trusted":true},"outputs":[],"source":["model.encoder.word_embeddings.weight = m.embeddings.word_embeddings.weight\n","# model.encoder.position_embeddings.pos_embeddings.weight =  m.embeddings.position_embeddings.weight"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T07:43:18.765193Z","iopub.status.busy":"2024-04-29T07:43:18.764944Z","iopub.status.idle":"2024-04-29T07:43:18.848476Z","shell.execute_reply":"2024-04-29T07:43:18.847513Z","shell.execute_reply.started":"2024-04-29T07:43:18.765171Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(10520, 4)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["dff = dff.sample(frac=0.02, random_state=42)\n","dff.shape"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T07:43:18.849934Z","iopub.status.busy":"2024-04-29T07:43:18.849594Z","iopub.status.idle":"2024-04-29T07:43:18.855538Z","shell.execute_reply":"2024-04-29T07:43:18.854671Z","shell.execute_reply.started":"2024-04-29T07:43:18.849902Z"},"trusted":true},"outputs":[],"source":["train_dataset = MLMDataset(text=dff[\"quote\"].values)\n","\n","train_loader = DataLoader(train_dataset, batch_size=128, shuffle=False, num_workers=2)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T07:43:18.857125Z","iopub.status.busy":"2024-04-29T07:43:18.856805Z","iopub.status.idle":"2024-04-29T07:43:18.872377Z","shell.execute_reply":"2024-04-29T07:43:18.871384Z","shell.execute_reply.started":"2024-04-29T07:43:18.857096Z"},"trusted":true},"outputs":[],"source":["from accelerate import Accelerator\n","import sys\n","\n","\n","def single_gpu():\n","    accumulation_steps = 1  # batch size 128 large dont need gradient accumulation\n","    lr = 1e-3\n","    EPOCHS = 10\n","    Config = {\n","        \"num_epoch\": EPOCHS,\n","        \"learning_rate\": lr,\n","        \"loss_function\": str(torch.nn.CrossEntropyLoss),\n","    }\n","\n","    accelerator = Accelerator(\n","        log_with=\"tensorboard\",\n","        project_dir=\".\",\n","    )\n","    accelerator.init_trackers(\"MLM_project\", config=Config)\n","\n","    model.cuda()\n","\n","    loss_fn = torch.nn.CrossEntropyLoss()\n","    optimizer = AdamW(model.parameters(), lr=lr)\n","    num_train_optimization_steps = int(EPOCHS * len(train_loader) / accumulation_steps)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps=0.05 * num_train_optimization_steps,\n","        num_training_steps=num_train_optimization_steps,\n","    )  # PyTorch scheduler\n","\n","    scaler = torch.cuda.amp.GradScaler()\n","    epoch_check = len(train_loader)\n","    total_step = epoch_check * EPOCHS\n","    train_bar = tqdm(total=total_step, dynamic_ncols=True)\n","    t_step = 1\n","    k = 0\n","    model.train()\n","    for epoch in range(EPOCHS):\n","        avg_loss = 0.0\n","        loss_list = []\n","        running_loss = 0.0\n","        for step, data in enumerate(train_loader):\n","            train_bar.update(1)\n","            #         train_bar.set_description(f\"step: {i+1} epoch: {epoch+1}\")\n","            input_ids, label, _ = masked_language_modeling(input_ids=data[\"input_ids\"])\n","            input_ids = input_ids.cuda()\n","            input_masks = data[\"attention_mask\"].cuda()\n","            label = label.long().cuda()\n","            with torch.cuda.amp.autocast():\n","                pred = model(input_ids, input_masks)\n","            loss = loss_fn(pred.logits.transpose(1, 2), label)\n","            scaler.scale(loss).backward()\n","            if step % accumulation_steps == 0:\n","                scaler.step(optimizer)\n","                scaler.update()\n","                optimizer.zero_grad()\n","            accelerator.log({\"training_loss_step\": loss}, step=t_step)\n","\n","            train_bar.set_description(\n","                f'epoch: {epoch+1} step: {t_step} loss: {\"%.4f\" % loss}'\n","            )\n","            t_step += 1\n","            #             running_loss += loss.detach().cpu().item()\n","            #             if t_step % 100 == 99:\n","            #                 last_loss = running_loss / 100 # loss per batch\n","            #                 print('  batch {} loss: {}'.format(t_step, last_loss))\n","            #                 accelerator.log({\"training_loss_100_step\": last_loss}, step= k)\n","            #                 running_loss = 0.0\n","            #                 k+=1\n","            #                 running_loss = 0.0\n","            loss_list.append(loss.detach().cpu().item())\n","        scheduler.step()\n","        avg_loss = np.round(np.mean(loss_list), 4)\n","        accelerator.log({\"training_loss_epoch\": avg_loss}, step=epoch + 1)\n","        print(f'Epoch: {epoch+1} loss: {\"%.4f\" % avg_loss }')\n","    accelerator.end_training()\n","    PATH = f\"encoder_mlm_{epoch}.pth\"\n","    torch.save(model.state_dict(), PATH)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T07:43:18.873634Z","iopub.status.busy":"2024-04-29T07:43:18.873379Z","iopub.status.idle":"2024-04-29T08:03:09.898704Z","shell.execute_reply":"2024-04-29T08:03:09.897508Z","shell.execute_reply.started":"2024-04-29T07:43:18.873612Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-04-29 07:43:20.898138: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-04-29 07:43:20.898246: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-04-29 07:43:21.027355: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3762f23ef20e49689143441b36366a42","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/830 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch: 1 loss: 10.9549\n","Epoch: 2 loss: 9.3715\n","Epoch: 3 loss: 7.5514\n","Epoch: 4 loss: 6.9679\n","Epoch: 5 loss: 6.4087\n","Epoch: 6 loss: 5.7537\n","Epoch: 7 loss: 5.3792\n","Epoch: 8 loss: 5.1183\n","Epoch: 9 loss: 4.9247\n","Epoch: 10 loss: 4.7339\n"]}],"source":[" single_gpu()"]},{"cell_type":"markdown","metadata":{},"source":["![MLM](../Images/MLM.png)"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T08:03:44.665239Z","iopub.status.busy":"2024-04-29T08:03:44.664520Z","iopub.status.idle":"2024-04-29T08:03:44.682216Z","shell.execute_reply":"2024-04-29T08:03:44.681295Z","shell.execute_reply.started":"2024-04-29T08:03:44.665203Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["stress shows on  the face.\n","stress shows on  your face.\n","stress shows on  their face.\n"]}],"source":["check = \"stress shows on <mask> face.\"\n","inputs = tokenizer(check, truncation=True, padding=True, return_tensors=\"pt\")\n","mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n","input_ids = inputs[\"input_ids\"].cuda()\n","attention_mask = inputs[\"attention_mask\"].cuda()\n","with torch.no_grad():\n","    logits = model(input_ids, attention_mask).logits\n","mask_token_logits = logits[0, mask_token_index, :]\n","top_3 = torch.topk(mask_token_logits, 3, dim=1).indices[0].tolist()\n","\n","for token in top_3:\n","    print(check.replace(tokenizer.mask_token, tokenizer.decode([token])))"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T08:03:45.809215Z","iopub.status.busy":"2024-04-29T08:03:45.808530Z","iopub.status.idle":"2024-04-29T08:03:45.824877Z","shell.execute_reply":"2024-04-29T08:03:45.823978Z","shell.execute_reply.started":"2024-04-29T08:03:45.809182Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["You are  not weak.\n","You are  a weak.\n","You are  too weak.\n"]}],"source":["check = \"You are <mask> weak.\"\n","inputs = tokenizer(check, truncation=True, padding=True, return_tensors=\"pt\")\n","mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n","input_ids = inputs[\"input_ids\"].cuda()\n","attention_mask = inputs[\"attention_mask\"].cuda()\n","with torch.no_grad():\n","    logits = model(input_ids, attention_mask).logits\n","mask_token_logits = logits[0, mask_token_index, :]\n","top_3 = torch.topk(mask_token_logits, 3, dim=1).indices[0].tolist()\n","\n","for token in top_3:\n","    print(check.replace(tokenizer.mask_token, tokenizer.decode([token])))"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T08:03:46.323907Z","iopub.status.busy":"2024-04-29T08:03:46.323535Z","iopub.status.idle":"2024-04-29T08:03:46.339938Z","shell.execute_reply":"2024-04-29T08:03:46.338965Z","shell.execute_reply.started":"2024-04-29T08:03:46.323875Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Get up and face your  own fears every day\n","Get up and face your  life fears every day\n","Get up and face your  heart fears every day\n"]}],"source":["check = \"Get up and face your <mask> fears every day\"\n","inputs = tokenizer(check, truncation=True, padding=True, return_tensors=\"pt\")\n","mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n","input_ids = inputs[\"input_ids\"].cuda()\n","attention_mask = inputs[\"attention_mask\"].cuda()\n","with torch.no_grad():\n","    logits = model(input_ids, attention_mask).logits\n","mask_token_logits = logits[0, mask_token_index, :]\n","top_3 = torch.topk(mask_token_logits, 3, dim=1).indices[0].tolist()\n","\n","for token in top_3:\n","    print(check.replace(tokenizer.mask_token, tokenizer.decode([token])))"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T08:03:46.922704Z","iopub.status.busy":"2024-04-29T08:03:46.922342Z","iopub.status.idle":"2024-04-29T08:03:46.939998Z","shell.execute_reply":"2024-04-29T08:03:46.939105Z","shell.execute_reply.started":"2024-04-29T08:03:46.922675Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["There is something , and something extremely profound, in owning a home.\n","There is something  good and something extremely profound, in owning a home.\n","There is something  that and something extremely profound, in owning a home.\n"]}],"source":["check = \"There is something <mask> and something extremely profound, in owning a home.\"\n","inputs = tokenizer(check, truncation=True, padding=True, return_tensors=\"pt\")\n","mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n","input_ids = inputs[\"input_ids\"].cuda()\n","attention_mask = inputs[\"attention_mask\"].cuda()\n","with torch.no_grad():\n","    logits = model(input_ids, attention_mask).logits\n","mask_token_logits = logits[0, mask_token_index, :]\n","top_3 = torch.topk(mask_token_logits, 3, dim=1).indices[0].tolist()\n","\n","for token in top_3:\n","    print(check.replace(tokenizer.mask_token, tokenizer.decode([token])))"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T08:03:48.047773Z","iopub.status.busy":"2024-04-29T08:03:48.047382Z","iopub.status.idle":"2024-04-29T08:03:48.064257Z","shell.execute_reply":"2024-04-29T08:03:48.063343Z","shell.execute_reply.started":"2024-04-29T08:03:48.047737Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["what is your  own my friend.\n","what is your  heart my friend.\n","what is your  mind my friend.\n"]}],"source":["check = \"what is your <mask> my friend.\"\n","inputs = tokenizer(check, truncation=True, padding=True, return_tensors=\"pt\")\n","mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n","input_ids = inputs[\"input_ids\"].cuda()\n","attention_mask = inputs[\"attention_mask\"].cuda()\n","with torch.no_grad():\n","    logits = model(input_ids, attention_mask).logits\n","mask_token_logits = logits[0, mask_token_index, :]\n","top_3 = torch.topk(mask_token_logits, 3, dim=1).indices[0].tolist()\n","\n","for token in top_3:\n","    print(check.replace(tokenizer.mask_token, tokenizer.decode([token])))"]},{"cell_type":"markdown","metadata":{},"source":["**To Get a better model you need to train it on large data and increase model size possibly 12 hidden layes like Bert/Roberta base**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T08:03:10.118218Z","iopub.status.busy":"2024-04-29T08:03:10.117940Z","iopub.status.idle":"2024-04-29T08:03:10.133166Z","shell.execute_reply":"2024-04-29T08:03:10.132313Z","shell.execute_reply.started":"2024-04-29T08:03:10.118194Z"},"trusted":true},"outputs":[],"source":["# logger = get_logger(__name__)\n","\n","\n","def main(train_loader=train_loader, model=model):\n","    lr = 1e-3\n","    EPOCHS = 4\n","    accumulation_steps = 1  # large batch =128 you don't need accumulation\n","\n","    loss_fn = torch.nn.CrossEntropyLoss()\n","    num_train_optimization_steps = int(EPOCHS * len(train_loader) / accumulation_steps)\n","    accelerator = Accelerator(\n","        log_with=\"tensorboard\", project_dir=\".\", mixed_precision=\"fp16\"\n","    )\n","    #     accelerator = Accelerator(mixed_precision='bf16')\n","    Config = {\n","        \"num_epoch\": EPOCHS,\n","        \"learning_rate\": lr,\n","        \"loss_function\": str(torch.nn.CrossEntropyLoss),\n","    }\n","\n","    accelerator.init_trackers(\"mlm_project\", config=Config)\n","\n","    optimizer = AdamW(model.parameters(), lr=lr)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps=0.05 * num_train_optimization_steps,\n","        num_training_steps=num_train_optimization_steps,\n","    )  # PyTorch scheduler\n","    model, optimizer, train_loader, scheduler = accelerator.prepare(\n","        model, optimizer, train_loader, scheduler\n","    )\n","    #     To launch a multi-GPU training from your notebook, the `Accelerator` should only be initialized inside your training function.\n","    #     Restart your notebook and make sure no cells initializes an `Accelerator`.\n","\n","    total_step = 1\n","    k = 0\n","    model.train()\n","    for epoch in range(EPOCHS):\n","        avg_loss = 0.0\n","        running_loss = 0.0\n","        tbar = tqdm(\n","            train_loader,\n","            disable=(not accelerator.is_local_main_process),\n","            file=sys.stdout,\n","        )\n","        loss_list = []\n","        for step, data in enumerate(tbar):\n","            input_ids, label, _ = masked_language_modeling(input_ids=data[\"input_ids\"])\n","            pred = model(input_ids, data[\"attention_mask\"])\n","            loss = loss_fn(pred.logits.transpose(1, 2), label)\n","            accelerator.backward(loss)\n","            optimizer.step()\n","            optimizer.zero_grad()\n","            loss_list.append(loss.detach().cpu().item())\n","            accelerator.log({\"training_loss_step\": loss}, step=total_step)\n","            total_step += 1\n","            running_loss += loss.detach().cpu().item()\n","            if total_step % 500 == 499:\n","                last_loss = running_loss / 500  # loss per batch\n","                accelerator.print(\"batch {} loss: {}\".format(total_step, last_loss))\n","                accelerator.log({\"training_loss_500_step\": last_loss}, step=k + 1)\n","                running_loss = 0.0\n","                k += 1\n","        scheduler.step()\n","        avg_loss = np.round(np.mean(loss_list), 4)\n","        accelerator.log({\"training_loss_epoch\": avg_loss}, step=epoch + 1)\n","        tbar.set_description(\n","            f\"Epoch {epoch + 1} Loss: {avg_loss} lr: {scheduler.get_last_lr()}\"\n","        )\n","        accelerator.print(f\"Epoch--{epoch+1} ### Train loss---{avg_loss}\")\n","\n","    PATH = f\"enocder_mlm_epoch__{epoch}.pth\"\n","    model_state_dict = accelerator.get_state_dict(model, unwrap=True)\n","    torch.save(model_state_dict, PATH)\n","    accelerator.print(f\"Model Saved--epoch--{epoch+1}\")\n","\n","    accelerator.end_training()\n","    accelerator.free_memory()\n","    del train_loader\n","    del model\n","    gc.collect()"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T08:03:10.134910Z","iopub.status.busy":"2024-04-29T08:03:10.134563Z","iopub.status.idle":"2024-04-29T08:03:10.144802Z","shell.execute_reply":"2024-04-29T08:03:10.144096Z","shell.execute_reply.started":"2024-04-29T08:03:10.134881Z"},"trusted":true},"outputs":[],"source":["from accelerate import notebook_launcher\n","\n","# notebook_launcher(main, num_processes=2)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":174422402,"sourceType":"kernelVersion"},{"sourceId":117289270,"sourceType":"kernelVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
