{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06df95b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:49:30.537910Z",
     "iopub.status.busy": "2025-02-20T18:49:30.537583Z",
     "iopub.status.idle": "2025-02-20T18:49:51.440548Z",
     "shell.execute_reply": "2025-02-20T18:49:51.439529Z"
    },
    "papermill": {
     "duration": 20.916504,
     "end_time": "2025-02-20T18:49:51.442468",
     "exception": false,
     "start_time": "2025-02-20T18:49:30.525964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import pickle\n",
    "import os\n",
    "import time \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import warnings\n",
    "import gc\n",
    "from accelerate import Accelerator\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "warnings.simplefilter('ignore')\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForCausalLM,AutoConfig\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86c02f00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:49:51.463620Z",
     "iopub.status.busy": "2025-02-20T18:49:51.463042Z",
     "iopub.status.idle": "2025-02-20T18:49:51.773928Z",
     "shell.execute_reply": "2025-02-20T18:49:51.772779Z"
    },
    "papermill": {
     "duration": 0.323424,
     "end_time": "2025-02-20T18:49:51.776004",
     "exception": false,
     "start_time": "2025-02-20T18:49:51.452580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 20 18:49:51 2025       \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\r\n",
      "|-----------------------------------------+------------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                        |               MIG M. |\r\n",
      "|=========================================+========================+======================|\r\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   34C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\r\n",
      "| N/A   36C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                              |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\r\n",
      "|        ID   ID                                                               Usage      |\r\n",
      "|=========================================================================================|\r\n",
      "|  No running processes found                                                             |\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71118836",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:49:51.797169Z",
     "iopub.status.busy": "2025-02-20T18:49:51.796779Z",
     "iopub.status.idle": "2025-02-20T18:49:59.307885Z",
     "shell.execute_reply": "2025-02-20T18:49:59.305371Z"
    },
    "papermill": {
     "duration": 7.524027,
     "end_time": "2025-02-20T18:49:59.309905",
     "exception": false,
     "start_time": "2025-02-20T18:49:51.785878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "470889d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:49:59.332384Z",
     "iopub.status.busy": "2025-02-20T18:49:59.331919Z",
     "iopub.status.idle": "2025-02-20T18:49:59.382443Z",
     "shell.execute_reply": "2025-02-20T18:49:59.381169Z"
    },
    "papermill": {
     "duration": 0.064601,
     "end_time": "2025-02-20T18:49:59.384625",
     "exception": false,
     "start_time": "2025-02-20T18:49:59.320024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import rearrange, reduce\n",
    "from typing import Optional, Tuple,Union,List\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "class AbsoluteEncoding(nn.Module):\n",
    "    def __init__(self, config) -> None:\n",
    "        super().__init__()\n",
    "        self.pos_embeddings = nn.Embedding(\n",
    "            config.max_position_embeddings, config.hidden_size\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"position_ids\",\n",
    "            torch.arange(config.max_position_embeddings).expand((1, -1)),\n",
    "            persistent=False,\n",
    "        )\n",
    "        self.max_size = config.max_position_embeddings\n",
    "\n",
    "    def forward(self, size: int) -> torch.Tensor:\n",
    "        if self.max_size < size:\n",
    "            raise ValueError(\n",
    "                f\"The hidden size ({size }) is more than the config max_position_embeddings {self.max_size}\"\n",
    "            )\n",
    "        return self.pos_embeddings(self.position_ids[:, :size])\n",
    "\n",
    "\n",
    "class SinusoidalEncoding(nn.Module):\n",
    "    def __init__(self, config) -> None:\n",
    "        super().__init__()\n",
    "        if config.hidden_size % 2 != 0:\n",
    "            raise ValueError(\n",
    "                f\"Cannot use SinusoidalEncoding with \"\n",
    "                \"odd hidden dim got dim {config.hidden_size}\"\n",
    "            )\n",
    "        self.positional_encoding = torch.zeros(\n",
    "            1, config.max_position_embeddings, config.hidden_size\n",
    "        )\n",
    "        self.position = torch.arange(0, config.max_position_embeddings).unsqueeze(1)\n",
    "        self.div_term = torch.exp(\n",
    "            (\n",
    "                torch.arange(0, config.hidden_size, 2, dtype=torch.float)\n",
    "                * -(torch.log(torch.tensor(10000.0)) / config.hidden_size)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.positional_encoding[:, :, 0::2] = torch.sin(\n",
    "            self.position.float() * self.div_term\n",
    "        )\n",
    "        self.positional_encoding[:, :, 1::2] = torch.cos(\n",
    "            self.position.float() * self.div_term\n",
    "        )\n",
    "\n",
    "    def forward(self, seq_len: int) -> torch.Tensor:\n",
    "\n",
    "        return self.positional_encoding[:, :seq_len]\n",
    "\n",
    "class RotaryEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    RotaryEmbedding is a PyTorch module that implements rotary positional embeddings for attention mechanisms.\n",
    "    Args:\n",
    "        config (object): Configuration object containing the following attributes:\n",
    "            hidden_size (int): The hidden size of the model.\n",
    "            num_attention_heads (int): The number of attention heads.\n",
    "    Attributes:\n",
    "        inv_freq (torch.Tensor): A tensor containing the inverse frequencies for the rotary embeddings.\n",
    "    Methods:\n",
    "        forward(seq_len):\n",
    "            Computes the rotary positional embeddings for a given sequence length.\n",
    "            Args:\n",
    "                seq_len (int): The length of the input sequence.\n",
    "            Returns:\n",
    "                torch.Tensor: A tensor containing the rotary positional embeddings with shape (1, seq_len, dim).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        dim = int(config.hidden_size // config.num_attention_heads)\n",
    "        inv_freq = 1.0 / (10000 ** (torch.arange(0, dim, 2).float() / dim))\n",
    "        self.register_buffer(\"inv_freq\", inv_freq)\n",
    "\n",
    "    def forward(self, seq_len):\n",
    "        t = torch.arange(seq_len, device=self.inv_freq.device).type_as(self.inv_freq)\n",
    "        freqs = torch.einsum(\"i, j -> i j\", t, self.inv_freq)\n",
    "\n",
    "        return freqs[None, :, :]\n",
    "\n",
    "\n",
    "def rotate_half(x):\n",
    "    \"\"\"\n",
    "    Rotates half the hidden dimensions of the input tensor.\n",
    "\n",
    "    Args:\n",
    "        x (torch.Tensor): The input tensor to be rotated.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The tensor with half of its hidden dimensions rotated.\n",
    "    \"\"\"\n",
    "    x1, x2 = x.chunk(2, dim=-1)\n",
    "    return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "\n",
    "# Copied from transformers.models.llama.modeling_llama.apply_rotary_pos_emb\n",
    "def apply_rotary_pos_emb(\n",
    "    q, k, freqs, only_q: bool = False, unsqueeze_dim=1\n",
    ") -> Tuple[torch.Tensor]:\n",
    "    \"\"\"Applies Rotary Position Embedding to the query and key tensors.\n",
    "\n",
    "    Args:\n",
    "        q (`torch.Tensor`): The query tensor.\n",
    "        k (`torch.Tensor`): The key tensor.\n",
    "        freqs: precalculated frqs for sin cos\n",
    "        only_q: bool = False for encoder decoder\n",
    "        unsqueeze_dim (`int`, *optional*, defaults to 1):\n",
    "            The 'unsqueeze_dim' argument specifies the dimension along which to unsqueeze cos[position_ids] and\n",
    "            sin[position_ids] so that they can be properly broadcasted to the dimensions of q and k. For example, note\n",
    "            that cos[position_ids] and sin[position_ids] have the shape [batch_size, seq_len, head_dim]. Then, if q and\n",
    "            k have the shape [batch_size, heads, seq_len, head_dim], then setting unsqueeze_dim=1 makes\n",
    "            cos[position_ids] and sin[position_ids] broadcastable to the shapes of q and k. Similarly, if q and k have\n",
    "            the shape [batch_size, seq_len, heads, head_dim], then set unsqueeze_dim=2.\n",
    "    Returns:\n",
    "        `tuple(torch.Tensor)` comprising of the query and key tensors rotated using the Rotary Position Embedding.\n",
    "    \"\"\"\n",
    "    emb = torch.cat((freqs, freqs), dim=-1)\n",
    "    cos = emb.cos()\n",
    "    sin = emb.sin()\n",
    "    cos = cos.unsqueeze(unsqueeze_dim)\n",
    "    sin = sin.unsqueeze(unsqueeze_dim)\n",
    "    #     print(cos.size(),sin.size(),q.size(),k.size())\n",
    "    if only_q:\n",
    "        q_embed = (q * cos) + (rotate_half(q) * sin)\n",
    "    else:\n",
    "\n",
    "        q_embed = (q * cos) + (rotate_half(q) * sin)\n",
    "        k_embed = (k * cos) + (rotate_half(k) * sin)\n",
    "        return q_embed, k_embed\n",
    "\n",
    "\n",
    "# To do :  Alibi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "328d4595",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:49:59.406027Z",
     "iopub.status.busy": "2025-02-20T18:49:59.405690Z",
     "iopub.status.idle": "2025-02-20T18:49:59.427677Z",
     "shell.execute_reply": "2025-02-20T18:49:59.426681Z"
    },
    "papermill": {
     "duration": 0.034554,
     "end_time": "2025-02-20T18:49:59.429405",
     "exception": false,
     "start_time": "2025-02-20T18:49:59.394851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionSelfOutput(nn.Module):\n",
    "    def __init__(\n",
    "        self, config, bias: Optional[bool] = True, out_features: Optional[int] = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(\n",
    "            config.hidden_size,\n",
    "            config.hidden_size if out_features is None else out_features,\n",
    "            bias=bias,\n",
    "        )\n",
    "        self.layernorm = nn.LayerNorm(\n",
    "            config.hidden_size, eps=getattr(config, \"layer_norm_eps\", 1e-6)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(getattr(config,'attention_dropout',0.0))\n",
    "\n",
    "    def forward(\n",
    "        self, hidden_states: torch.Tensor, input_tensor: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            hidden_states: torch.FloatTensor of shape (batch, seq_len, embed_dim)`\n",
    "            input_tensor: torch.FloatTensor of shape (batch, seq_len, embed_dim)`\n",
    "\n",
    "        return:\n",
    "               hidden_states: torch.FloatTensor of shape (batch, seq_len, embed_dim)\n",
    "\n",
    "        \"\"\"\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.layernorm(hidden_states + input_tensor)\n",
    "        return hidden_states\n",
    "        \n",
    "\n",
    "class DecoderAttention(nn.Module):\n",
    "    def __init__(self, config, layer_idx: int) -> None:\n",
    "        super().__init__()\n",
    "        if config.hidden_size % config.num_attention_heads != 0:\n",
    "            raise ValueError(\n",
    "                f\"The hidden size ({config.hidden_size}) is not a multiple of the number of attention \"\n",
    "                f\"heads ({config.num_attention_heads})\"\n",
    "            )\n",
    "        self.head_size = int(config.hidden_size // config.num_attention_heads)\n",
    "        self.attention_bias = getattr(config, \"attention_bias\", True)\n",
    "        self.layer_idx = layer_idx\n",
    "        # self.qkv = nn.Linear(config.hidden_size,3*config.hidden_size)\n",
    "        self.query = nn.Linear(\n",
    "            config.hidden_size, config.hidden_size, bias=self.attention_bias\n",
    "        )\n",
    "        self.key = nn.Linear(\n",
    "            config.hidden_size, config.hidden_size, bias=self.attention_bias\n",
    "        )\n",
    "        self.value = nn.Linear(\n",
    "            config.hidden_size, config.hidden_size, bias=self.attention_bias\n",
    "        )\n",
    "        self.out = AttentionSelfOutput(config=config, bias=self.attention_bias)\n",
    "        self.num_attention_heads = config.num_attention_heads\n",
    "        self.flash = hasattr(torch.nn.functional, \"scaled_dot_product_attention\")\n",
    "        if not self.flash and self.layer_idx == 0:  # avoid to print m times:\n",
    "            print(\"WARNING: Flash Attention requires PyTorch >= 2.0\")\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_state: torch.Tensor,\n",
    "        attention_mask: torch.Tensor,\n",
    "        freqs: Optional[torch.Tensor] = None,\n",
    "        use_cache: Optional[bool] = False,\n",
    "        kv_cache: List[torch.FloatTensor] = None,\n",
    "        start_pos: Optional[int] = 0,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            hidden_states: torch.Tensor of shape (batch, seq_len, embed_dim)`\n",
    "            Attention_mask: torch.Tensor of shape (batch,1, seq_len, seqlen)`\n",
    "            freqs: Positional freqs in case of RoPE embedding\n",
    "            use_cace: Optional to use kvCache\n",
    "            start_pos: in case of kvCache to get store kv-cache at start_pos\n",
    "        return:\n",
    "               hidden_states: torch.Tensor of shape (batch, seq_len, embed_dim)\n",
    "\n",
    "        \"\"\"\n",
    "        q = self.query(hidden_state)\n",
    "        k = self.key(hidden_state)\n",
    "        v = self.value(hidden_state)\n",
    "        # transform it into batch_size x no_of_heads x seqlen x head_dim for Multihead Attention\n",
    "        q = rearrange(q, \"b l (h d) -> b h l d\", h=self.num_attention_heads)\n",
    "        k = rearrange(k, \"b l (h d) -> b h l d\", h=self.num_attention_heads)\n",
    "        v = rearrange(v, \"b l (h d) -> b h l d\", h=self.num_attention_heads)\n",
    "\n",
    "        if freqs is not None:\n",
    "            q, k = apply_rotary_pos_emb(q, k, freqs)  # apply RoPE if freqs is available\n",
    "\n",
    "        if use_cache:\n",
    "            if kv_cache is None:\n",
    "                raise ValueError(\"you need to pass kv_cache\")\n",
    "            k, v = kv_cache.update(self.layer_idx, k, v, start_pos)\n",
    "\n",
    "        out = torch.nn.functional.scaled_dot_product_attention(\n",
    "            query=q, key=k, value=v, attn_mask=attention_mask\n",
    "        )\n",
    "        # transform it back into batch_size x seqlen x hidden_dim\n",
    "        out = rearrange(out, \"b h l d -> b l (h d)\")\n",
    "\n",
    "        return self.out(out, hidden_state), kv_cache\n",
    "\n",
    "def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    This is the equivalent of torch.repeat_interleave(x, dim=1, repeats=n_rep). The hidden states go from (batch,\n",
    "    num_key_value_heads, seqlen, head_dim) to (batch, num_attention_heads, seqlen, head_dim)\n",
    "    \"\"\"\n",
    "    batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
    "    if n_rep == 1:\n",
    "        return hidden_states\n",
    "    hidden_states = hidden_states[:, :, None, :, :].expand(\n",
    "        batch, num_key_value_heads, n_rep, slen, head_dim\n",
    "    )\n",
    "    return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
    "\n",
    "\n",
    "class DecoderAttentionGqa(nn.Module):\n",
    "    def __init__(self, config, layer_idx: int) -> None:\n",
    "        super().__init__()\n",
    "        if config.hidden_size % config.num_attention_heads != 0:\n",
    "            raise ValueError(\n",
    "                f\"The hidden size ({config.hidden_size}) is not a multiple of the number of attention \"\n",
    "                f\"heads ({config.num_attention_heads})\"\n",
    "            )\n",
    "        self.flash = hasattr(torch.nn.functional, \"scaled_dot_product_attention\")\n",
    "        if not self.flash and self.layer_idx == 0:  # avoid to print m times\n",
    "            print(\"WARNING: Flash Attention requires PyTorch >= 2.0\")\n",
    "        self.layer_idx = layer_idx\n",
    "        self.head_dim = int(config.hidden_size // config.num_attention_heads)\n",
    "        self.num_attention_heads = config.num_attention_heads\n",
    "        self.num_key_value_heads = getattr(config, \"num_key_value_heads\", 4)\n",
    "        self.num_key_value_groups = self.num_attention_heads // self.num_key_value_heads\n",
    "        if (\n",
    "            self.num_attention_heads % self.num_key_value_heads != 0\n",
    "            or self.num_attention_heads < self.num_key_value_heads\n",
    "        ):\n",
    "            raise ValueError(\n",
    "                f\"num_key_value_heads {self.num_key_value_heads }  should be less than equal num_attention_heads {config.num_attention_heads} and  multiple of num_attention_heads {config.num_attention_heads} \"\n",
    "            )\n",
    "        self.attention_bias = getattr(config, \"attention_bias\", True)\n",
    "        self.out = AttentionSelfOutput(config=config, bias=self.attention_bias)\n",
    "        self.query = nn.Linear(\n",
    "            config.hidden_size, config.hidden_size, bias=self.attention_bias\n",
    "        )\n",
    "        self.key = nn.Linear(\n",
    "            config.hidden_size,\n",
    "            self.num_key_value_heads * self.head_dim,\n",
    "            bias=self.attention_bias,\n",
    "        )\n",
    "        self.value = nn.Linear(\n",
    "            config.hidden_size,\n",
    "            self.num_key_value_heads * self.head_dim,\n",
    "            bias=self.attention_bias,\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_state: torch.Tensor,\n",
    "        attention_mask: torch.Tensor,\n",
    "        freqs: Optional[torch.Tensor] = None,\n",
    "        use_cache: Optional[bool] = False,\n",
    "        kv_cache: List[torch.FloatTensor] = None,\n",
    "        start_pos: Optional[int] = 0,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            hidden_states: torch.Tensor of shape (batch, seq_len, embed_dim)`\n",
    "            Attention_mask: torch.Tensor of shape (batch,1, seq_len, seqlen)`\n",
    "            freqs: Positional freqs in case of RoPE embedding\n",
    "            use_cace: Optional to use kvCache\n",
    "            start_pos: in case of kvCache to get store kv-cache at start_pos\n",
    "        return:\n",
    "               hidden_states: torch.Tensor of shape (batch, seq_len, embed_dim)\n",
    "\n",
    "        \"\"\"\n",
    "        q = self.query(hidden_state)\n",
    "        k = self.key(hidden_state)\n",
    "        v = self.value(hidden_state)\n",
    "        # transform it into batch_size x no_of_heads x seqlen x head_dim for Multihead Attention\n",
    "        q = rearrange(q, \"b l (h d) -> b h l d\", d=self.head_dim)\n",
    "        k = rearrange(k, \"b l (h d) -> b h l d\", d=self.head_dim)\n",
    "        v = rearrange(v, \"b l (h d) -> b h l d\", d=self.head_dim)\n",
    "        if freqs is not None:\n",
    "            q, k = apply_rotary_pos_emb(q, k, freqs)  # apply RoPE if freqs is available\n",
    "\n",
    "        if use_cache:\n",
    "            if kv_cache is None:\n",
    "                raise ValueError(\"you need to pass kv_cache\")\n",
    "            k, v = kv_cache.update(self.layer_idx, k, v, start_pos)\n",
    "\n",
    "        k = repeat_kv(\n",
    "            k, n_rep=self.num_key_value_groups\n",
    "        )  # in case of GQA repeat k,v to make it same as q\n",
    "        v = repeat_kv(v, n_rep=self.num_key_value_groups)\n",
    "\n",
    "        out = torch.nn.functional.scaled_dot_product_attention(\n",
    "            query=q, key=k, value=v, attn_mask=attention_mask\n",
    "        )\n",
    "        # transform it back into batch_size x seqlen x hidden_dim\n",
    "        out = rearrange(out, \"b h l d -> b l (h d)\")\n",
    "\n",
    "        return self.out(out, hidden_state), kv_cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7abdbe07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:49:59.451050Z",
     "iopub.status.busy": "2025-02-20T18:49:59.450715Z",
     "iopub.status.idle": "2025-02-20T18:49:59.458893Z",
     "shell.execute_reply": "2025-02-20T18:49:59.457935Z"
    },
    "papermill": {
     "duration": 0.021292,
     "end_time": "2025-02-20T18:49:59.460594",
     "exception": false,
     "start_time": "2025-02-20T18:49:59.439302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ACT_ = {\n",
    "    \"gelu\": nn.GELU(),\n",
    "    \"leaky_relu\": nn.LeakyReLU(),\n",
    "    \"relu6\": nn.ReLU6(),\n",
    "    \"sigmoid\": nn.Sigmoid(),\n",
    "    \"silu\": nn.SiLU(),\n",
    "    \"swish\": nn.SiLU(),\n",
    "    \"tanh\": nn.Tanh(),\n",
    "}\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, config, multiplier: Union[int, float] = 4) -> None:\n",
    "        super().__init__()\n",
    "        self.intermediate = nn.Linear(\n",
    "            config.hidden_size, int(multiplier) * config.hidden_size\n",
    "        )\n",
    "        self.dropout = nn.Dropout(getattr(config,'attention_dropout',0.0))\n",
    "        self.layerNorm = nn.LayerNorm(config.hidden_size, eps=getattr(config,'layer_norm_eps',1e-6))\n",
    "        if _ACT_.get(getattr(config, \"hidden_act\", None), None):\n",
    "            self.act_fn = _ACT_[config.hidden_act]\n",
    "        else:\n",
    "            self.act_fn = nn.GELU()\n",
    "        self.out = nn.Linear(int(multiplier) * config.hidden_size, config.hidden_size)\n",
    "\n",
    "    def forward(\n",
    "        self, hidden_state: torch.Tensor, input_tensor: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        output = self.intermediate(hidden_state)\n",
    "        output = self.act_fn(output)\n",
    "        output = self.out(output)\n",
    "        output = self.dropout(output)\n",
    "        output = self.layerNorm(output + input_tensor)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba10f985",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:49:59.482893Z",
     "iopub.status.busy": "2025-02-20T18:49:59.482555Z",
     "iopub.status.idle": "2025-02-20T18:49:59.502060Z",
     "shell.execute_reply": "2025-02-20T18:49:59.500839Z"
    },
    "papermill": {
     "duration": 0.033192,
     "end_time": "2025-02-20T18:49:59.503856",
     "exception": false,
     "start_time": "2025-02-20T18:49:59.470664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mainly 2way to do one keep it into the model init like llama https://github.com/meta-llama/llama/blob/main/llama/model.py\n",
    "# every attention layer have its own kv-cache storage\n",
    "# or keep all attention layer kv-cache into single storage like Huggingface Transformer\n",
    "\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, Generator, List, Optional, Tuple\n",
    "import torch\n",
    "\n",
    "\n",
    "class DynamicCache:\n",
    "    \"\"\"\n",
    "    A cache that grows dynamically as more tokens are generated.\n",
    "\n",
    "    It stores the Key and Value states as a list of tensors, one for each layer. The expected shape for each tensor is\n",
    "    `[batch_size, num_heads, seq_len, head_dim]`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, is_gqa: bool = False) -> None:\n",
    "        self.key_cache: List[torch.Tensor] = []\n",
    "        self.value_cache: List[torch.Tensor] = []\n",
    "        self._seen_tokens = False\n",
    "\n",
    "        self.layers = config.num_hidden_layers\n",
    "        for _ in range(self.layers):\n",
    "            self.key_cache.append([])\n",
    "            self.value_cache.append([])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Support for backwards-compatible `past_key_value` length, e.g. `len(past_key_value)`. This value corresponds\n",
    "        to the number of layers in the model.\n",
    "        \"\"\"\n",
    "        if len(self.key_cache) == 0:\n",
    "            return 0\n",
    "        return self.key_cache[0].shape[-2]\n",
    "\n",
    "    def update(\n",
    "        self,\n",
    "        index: int,\n",
    "        key_states: torch.Tensor,\n",
    "        value_states: torch.Tensor,\n",
    "        start_pos: int = 0,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Updates the cache with the new `key_states` and `value_states` for the layer `layer_idx`.\n",
    "\n",
    "        Parameters:\n",
    "            key_states (`torch.Tensor`):\n",
    "                The new key states to cache.\n",
    "            value_states (`torch.Tensor`):\n",
    "                The new value states to cache.\n",
    "            layer_idx (`int`):\n",
    "                The index of the layer to cache the states for.\n",
    "            cache_kwargs (`Dict[str, Any]`, `optional`):\n",
    "                Additional arguments for the cache subclass. No additional arguments are used in `DynamicCache`.\n",
    "\n",
    "        Return:\n",
    "            A tuple containing the updated key and value states.\n",
    "        \"\"\"\n",
    "\n",
    "        # Update the cache first iteration'\n",
    "\n",
    "        if len(self.key_cache[index]) == 0:\n",
    "            self._seen_tokens = True\n",
    "            self.key_cache[index] = key_states.clone()\n",
    "            self.value_cache[index] = value_states.clone()\n",
    "        else:\n",
    "            self.key_cache[index] = torch.cat(\n",
    "                [self.key_cache[index], key_states], dim=-2\n",
    "            )\n",
    "            self.value_cache[index] = torch.cat(\n",
    "                [self.value_cache[index], value_states], dim=-2\n",
    "            )\n",
    "\n",
    "        return self.key_cache[index], self.value_cache[index]\n",
    "\n",
    "    def get(self, index: int) -> Tuple[torch.Tensor]:\n",
    "        if self._seen_tokens:\n",
    "            return self.key_cache[index], self.value_cache[index]\n",
    "        else:\n",
    "            raise ValueError(\"there is no token available in kv-cache\")\n",
    "\n",
    "    def get_seq_length(self, layer_idx: Optional[int] = 0) -> int:\n",
    "        \"\"\"Returns the sequence length of the cached states. A layer index can be optionally passed.\"\"\"\n",
    "        if self.key_cache is None:\n",
    "            return 0\n",
    "        return self.key_cache[layer_idx].shape[-2]\n",
    "\n",
    "    def get_max_length(self) -> Optional[int]:\n",
    "        \"\"\"Returns the maximum sequence length of the cached states. DynamicCache does not have a maximum length.\"\"\"\n",
    "        return self.max_cache_len\n",
    "\n",
    "\n",
    "class StaticCache:\n",
    "    \"\"\"\n",
    "    A cache that grows dynamically as more tokens are generated.\n",
    "\n",
    "    It stores the Key and Value states as a list of tensors, one for each layer. The expected shape for each tensor is\n",
    "    `[batch_size, num_heads, seq_len, head_dim]`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        max_cache_len: int = None,\n",
    "        dtype: torch.dtype = torch.float32,\n",
    "        batch_size: int = 1,\n",
    "        is_gqa: bool = False,\n",
    "    ) -> None:\n",
    "        self.head_size = int(config.hidden_size // config.num_attention_heads)\n",
    "        self.heads = None\n",
    "        self.batch_size = batch_size\n",
    "        # if is_gqa:\n",
    "        self.heads = getattr(config, \"num_key_value_heads\", None)\n",
    "        # if self.heads is None:\n",
    "        #     raise ValueError(\n",
    "        #         \"you are using is_gqa=True and config.num_key_value_heads is not available\"\n",
    "        #     )\n",
    "        if self.heads is None:\n",
    "\n",
    "            self.heads = config.num_attention_heads\n",
    "\n",
    "        self.max_cache_len = (\n",
    "            config.max_position_embeddings if max_cache_len is None else max_cache_len\n",
    "        )\n",
    "\n",
    "        self.dtype = dtype\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.key_cache: List[torch.Tensor] = []\n",
    "        self.value_cache: List[torch.Tensor] = []\n",
    "\n",
    "        self.cache_shape = (\n",
    "            self.batch_size,\n",
    "            self.heads,\n",
    "            self.max_cache_len,\n",
    "            self.head_size,\n",
    "        )\n",
    "\n",
    "        self._seen_tokens = False\n",
    "        self.layers = config.num_hidden_layers\n",
    "        for _ in range(self.layers):\n",
    "            blank_key_cache = torch.zeros(\n",
    "                self.cache_shape, dtype=self.dtype, device=self.device\n",
    "            )\n",
    "            blank_value_cache = torch.zeros(\n",
    "                self.cache_shape, dtype=self.dtype, device=self.device\n",
    "            )\n",
    "            self.key_cache.append(blank_key_cache)\n",
    "            self.value_cache.append(blank_value_cache)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        if self.key_cache is None:\n",
    "            return 0\n",
    "        \"\"\"\n",
    "        Support for backwards-compatible `past_key_value` length, e.g. `len(past_key_value)`. This value corresponds\n",
    "        to the number of layers in the model.\n",
    "        \"\"\"\n",
    "        return self.key_cache.shape[-2]\n",
    "\n",
    "    def update(\n",
    "        self,\n",
    "        index: int,\n",
    "        key_states: torch.Tensor,\n",
    "        value_states: torch.Tensor,\n",
    "        start_pos: int = 0,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Updates the cache with the new `key_states` and `value_states` for the layer `layer_idx`.\n",
    "\n",
    "        Parameters:\n",
    "            key_states (`torch.Tensor`):\n",
    "                The new key states to cache.\n",
    "            value_states (`torch.Tensor`):\n",
    "                The new value states to cache.\n",
    "            layer_idx (`int`):\n",
    "                The index of the layer to cache the states for.\n",
    "            cache_kwargs (`Dict[str, Any]`, `optional`):\n",
    "                Additional arguments for the cache subclass. No additional arguments are used in `DynamicCache`.\n",
    "\n",
    "        Return:\n",
    "            A tuple containing the updated key and value states.\n",
    "        \"\"\"\n",
    "\n",
    "        # Update the cache first iteration'\n",
    "\n",
    "        bsz, head, seqlen, _ = key_states.shape\n",
    "        if seqlen > self.key_cache[index].size()[2]:\n",
    "            raise ValueError(\n",
    "                f\"{k.shape} is more than init k_cache size {self.key_cache}\"\n",
    "            )\n",
    "\n",
    "        self.key_cache[index][:bsz, :, start_pos : start_pos + seqlen] = key_states\n",
    "        self.value_cache[index][:bsz, :, start_pos : start_pos + seqlen] = value_states\n",
    "\n",
    "        k = self.key_cache[index][:bsz, :, : start_pos + seqlen]\n",
    "        v = self.value_cache[index][:bsz, :, : start_pos + seqlen]\n",
    "\n",
    "        return k, v\n",
    "\n",
    "    def get(self, index: int) -> Tuple[torch.Tensor]:\n",
    "        if self._seen_tokens:\n",
    "            return self.key_cache[index], self.value_cache[index]\n",
    "        else:\n",
    "            raise ValueError(\"there is no token available in kv-cache\")\n",
    "\n",
    "    def get_seq_length(self, layer_idx: Optional[int] = 0) -> int:\n",
    "        \"\"\"Returns the sequence length of the cached states. A layer index can be optionally passed.\"\"\"\n",
    "        if self.key_cache is None:\n",
    "            return 0\n",
    "        return self.key_cache[layer_idx].shape[-2]\n",
    "\n",
    "    def get_max_length(self) -> Optional[int]:\n",
    "        \"\"\"Returns the maximum sequence length of the cached states. DynamicCache does not have a maximum length.\"\"\"\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd39ce56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:49:59.525553Z",
     "iopub.status.busy": "2025-02-20T18:49:59.524999Z",
     "iopub.status.idle": "2025-02-20T18:49:59.549344Z",
     "shell.execute_reply": "2025-02-20T18:49:59.548222Z"
    },
    "papermill": {
     "duration": 0.037492,
     "end_time": "2025-02-20T18:49:59.551299",
     "exception": false,
     "start_time": "2025-02-20T18:49:59.513807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GPT style model Casual language modeling\n",
    "\n",
    "_position_embeddings = {\n",
    "    \"absolute\": AbsoluteEncoding,\n",
    "    \"sinusoidal\": SinusoidalEncoding,\n",
    "}\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DecoderOutput(object):\n",
    "    logits: torch.Tensor\n",
    "    past_key_value: Optional[object]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CLMOutput(object):\n",
    "    hidden_state: torch.Tensor\n",
    "    logits: torch.Tensor\n",
    "    kv_cache: List[torch.FloatTensor] = None\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, config, layer_idx: int, attention_type: str = None) -> None:\n",
    "        super().__init__()\n",
    "        self.attention = (\n",
    "            DecoderAttentionGqa(config, layer_idx=layer_idx)\n",
    "            if attention_type == \"gqa\"\n",
    "            else DecoderAttention(config, layer_idx=layer_idx)\n",
    "        )\n",
    "        if attention_type == \"gqa\" and layer_idx == 0:  # avoid to print m times\n",
    "            print(\"Decoder Using GQA Attention\")\n",
    "        self.feed_forward = FeedForward(config)\n",
    "        self.layer_idx = layer_idx\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_state: torch.Tensor,\n",
    "        attention_mask: torch.Tensor,\n",
    "        freqs: Optional[torch.Tensor] = None,\n",
    "        use_cache: Optional[bool] = False,\n",
    "        kv_cache: List[torch.FloatTensor] = None,\n",
    "        start_pos: Optional[int] = 0,\n",
    "    ) -> torch.Tensor:\n",
    "        out,kv_cache = self.attention(\n",
    "            hidden_state=hidden_state,\n",
    "            attention_mask=attention_mask,\n",
    "            freqs=freqs,\n",
    "            use_cache=use_cache,\n",
    "            kv_cache=kv_cache,\n",
    "            start_pos=start_pos,\n",
    "        )\n",
    "        out = self.feed_forward(out, hidden_state)\n",
    "        return out, kv_cache\n",
    "\n",
    "\n",
    "class LMHead(nn.Module):\n",
    "    \"\"\"Head for masked language modelling\"\"\"\n",
    "\n",
    "    def __init__(self, config) -> None:\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.layerNorm = nn.LayerNorm(config.hidden_size, eps=getattr(config,'layer_norm_eps',1e-6))\n",
    "\n",
    "        self.decoder = nn.Linear(config.hidden_size, config.vocab_size)\n",
    "        self.bias = nn.Parameter(torch.zeros(config.vocab_size))\n",
    "        self.decoder.bias = self.bias\n",
    "\n",
    "    def forward(self, hidden_state: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.dense(hidden_state)\n",
    "        x = nn.GELU()(x)\n",
    "        x = self.layerNorm(x)\n",
    "\n",
    "        # project back to size of vocabulary with bias\n",
    "        x = self.decoder(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class DecoderModel(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        pos_embedding_type: Optional[str] = \"absolute\",\n",
    "        attention_type: str = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.word_embeddings = nn.Embedding(\n",
    "            config.vocab_size,\n",
    "            config.hidden_size,\n",
    "            padding_idx=getattr(config, \"pad_token_id\", None),\n",
    "        )\n",
    "        if _position_embeddings.get(pos_embedding_type, None) is not None:\n",
    "            self.position_embeddings = _position_embeddings.get(pos_embedding_type)(\n",
    "                config\n",
    "            )\n",
    "        else:\n",
    "            self.position_embeddings = None\n",
    "        if pos_embedding_type == \"rope\":\n",
    "            self.emb_freq = RotaryEmbedding(config)(config.max_position_embeddings)\n",
    "            print(\n",
    "                \"Encoder Ignoring sinusoidal or absolute position embeddings because rope,is enable\"\n",
    "            )\n",
    "        self.all_layer = nn.ModuleList(\n",
    "            [\n",
    "                DecoderLayer(config, layer_idx, attention_type)\n",
    "                for layer_idx in range(config.num_hidden_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.lm_head = LMHead(config=config)\n",
    "        self.config = config\n",
    "\n",
    "    def _init_weights(self, module: nn.Module) -> None:\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(\n",
    "                module.weight, mean=0.0, std=0.02 / torch.sqrt(2 * len(self.all_layer))\n",
    "            )\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(\n",
    "                module.weight, mean=0.0, std=0.02 / torch.sqrt(2 * len(self.all_layer))\n",
    "            )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        use_cache: Optional[bool] = False,\n",
    "        kv_cache: List[torch.FloatTensor] = None,\n",
    "        start_pos: Optional[int] = 0,\n",
    "    ) -> torch.Tensor:\n",
    "        _bsz, seqlen = input_ids.shape\n",
    "        hidden_state = self.word_embeddings(input_ids)\n",
    "        freqs = None\n",
    "        if self.position_embeddings is not None:\n",
    "            pos_info = self.position_embeddings(start_pos + seqlen)[\n",
    "                :, start_pos : start_pos + seqlen, :\n",
    "            ].to(input_ids.device)\n",
    "            hidden_state = hidden_state + pos_info\n",
    "        else:\n",
    "            freqs = self.emb_freq[:, start_pos : start_pos + seqlen].to(\n",
    "                input_ids.device\n",
    "            )\n",
    "        mask = None\n",
    "        if seqlen > 1:\n",
    "            mask = self.create_mask_for_decoder(\n",
    "                input_ids=input_ids, attention_mask=attention_mask, start_pos=start_pos\n",
    "            )\n",
    "            mask = (1.0 - mask) * torch.finfo(\n",
    "                hidden_state.dtype\n",
    "            ).min  # invert it to to add directly to attention score\n",
    "\n",
    "        for layer in self.all_layer:\n",
    "            hidden_state, kv_cache = layer(\n",
    "                hidden_state,\n",
    "                mask,\n",
    "                freqs=freqs,\n",
    "                use_cache=use_cache,\n",
    "                kv_cache=kv_cache,\n",
    "                start_pos=start_pos,\n",
    "            )\n",
    "        logits = self.lm_head(hidden_state)\n",
    "        return CLMOutput(hidden_state=hidden_state, logits=logits, kv_cache=kv_cache)\n",
    "\n",
    "    def create_mask_for_decoder(\n",
    "        self,\n",
    "        input_ids,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        start_pos: Optional[int] = 0,\n",
    "    ) -> torch.Tensor:\n",
    "        device = input_ids.device\n",
    "        batch_size, seq_length = input_ids.shape\n",
    "        if attention_mask is None:\n",
    "            attention_mask = (\n",
    "                torch.ones(seq_length + start_pos).repeat(batch_size, 1).to(device)\n",
    "            )\n",
    "        seq_ids = torch.arange(seq_length).to(device)\n",
    "        causal_mask = (\n",
    "            seq_ids[None, None, :].repeat(batch_size, seq_length, 1)\n",
    "            <= seq_ids[None, :, None]\n",
    "        )  # 1x1xl repeat bxlxl compare to 1xlx1\n",
    "\n",
    "        causal_mask = causal_mask.to(attention_mask.dtype)\n",
    "\n",
    "        if start_pos > 0:  # correct the attention mask  for kv-cache operation\n",
    "            causal_mask = torch.cat(\n",
    "                [\n",
    "                    torch.ones(\n",
    "                        (batch_size, seq_length, start_pos),\n",
    "                        device=device,\n",
    "                        dtype=causal_mask.dtype,\n",
    "                    ),\n",
    "                    causal_mask,\n",
    "                ],\n",
    "                axis=-1,\n",
    "            )\n",
    "\n",
    "        extended_attention_mask = (\n",
    "            causal_mask[:, None, :, :] * attention_mask[:, None, None, :]\n",
    "        )  # # this is mainly if batch contains <PAD> tokens. stop casual procees before <PAD>\n",
    "        return extended_attention_mask\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(\n",
    "        cls,\n",
    "        config,\n",
    "        pos_embedding_type: Optional[str] = \"absolute\",\n",
    "        attention_type: Optional[str] = None,\n",
    "    ) -> nn.Module:\n",
    "        return cls(config, pos_embedding_type, attention_type)\n",
    "\n",
    "    def _setup_cache(self, config, cls: Optional[object] = StaticCache) -> None:\n",
    "        for layer in self.all_layer:\n",
    "            layer.attention.cache = cls(config)\n",
    "\n",
    "    def _clean_cache(self) -> None:\n",
    "        for layer in self.all_layer:\n",
    "            layer.attention.cache = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c9e96bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:49:59.572530Z",
     "iopub.status.busy": "2025-02-20T18:49:59.572041Z",
     "iopub.status.idle": "2025-02-20T18:49:59.576481Z",
     "shell.execute_reply": "2025-02-20T18:49:59.575425Z"
    },
    "papermill": {
     "duration": 0.01682,
     "end_time": "2025-02-20T18:49:59.578162",
     "exception": false,
     "start_time": "2025-02-20T18:49:59.561342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36cebf7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:49:59.598999Z",
     "iopub.status.busy": "2025-02-20T18:49:59.598634Z",
     "iopub.status.idle": "2025-02-20T18:50:27.262681Z",
     "shell.execute_reply": "2025-02-20T18:50:27.261546Z"
    },
    "papermill": {
     "duration": 27.676696,
     "end_time": "2025-02-20T18:50:27.264694",
     "exception": false,
     "start_time": "2025-02-20T18:49:59.587998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "m =AutoModelForCausalLM.from_pretrained(\"../input/transformer-distilation-gpt-2/gpt2_6L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc5a6ffb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:50:27.286633Z",
     "iopub.status.busy": "2025-02-20T18:50:27.285909Z",
     "iopub.status.idle": "2025-02-20T18:50:28.692927Z",
     "shell.execute_reply": "2025-02-20T18:50:28.691147Z"
    },
    "papermill": {
     "duration": 1.420344,
     "end_time": "2025-02-20T18:50:28.695136",
     "exception": false,
     "start_time": "2025-02-20T18:50:27.274792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "895c619d7ec746a99c717b6c4ad54714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4124b319a26d405c902f8084dbcbcddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33edbfb8b5d9426aaf9145d3be954a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac1ed4ec37440e48b4010bbdeeb523c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "356fe8d190d34fe5a87f069cc618af45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19272a3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:50:28.719379Z",
     "iopub.status.busy": "2025-02-20T18:50:28.718940Z",
     "iopub.status.idle": "2025-02-20T18:50:28.725090Z",
     "shell.execute_reply": "2025-02-20T18:50:28.723961Z"
    },
    "papermill": {
     "duration": 0.020344,
     "end_time": "2025-02-20T18:50:28.726942",
     "exception": false,
     "start_time": "2025-02-20T18:50:28.706598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82ed0d58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:50:28.750455Z",
     "iopub.status.busy": "2025-02-20T18:50:28.749983Z",
     "iopub.status.idle": "2025-02-20T18:50:28.754942Z",
     "shell.execute_reply": "2025-02-20T18:50:28.753601Z"
    },
    "papermill": {
     "duration": 0.018818,
     "end_time": "2025-02-20T18:50:28.756805",
     "exception": false,
     "start_time": "2025-02-20T18:50:28.737987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if tokenizer.pad_token_id is None:\n",
    "  tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Set reasonable default for models without max length\n",
    "if tokenizer.model_max_length > 512:\n",
    "  tokenizer.model_max_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56d582b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:50:28.780047Z",
     "iopub.status.busy": "2025-02-20T18:50:28.779641Z",
     "iopub.status.idle": "2025-02-20T18:50:28.785612Z",
     "shell.execute_reply": "2025-02-20T18:50:28.784471Z"
    },
    "papermill": {
     "duration": 0.019729,
     "end_time": "2025-02-20T18:50:28.787598",
     "exception": false,
     "start_time": "2025-02-20T18:50:28.767869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "state_dict = m.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c66dabdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:50:28.811277Z",
     "iopub.status.busy": "2025-02-20T18:50:28.810791Z",
     "iopub.status.idle": "2025-02-20T18:50:28.916729Z",
     "shell.execute_reply": "2025-02-20T18:50:28.915502Z"
    },
    "papermill": {
     "duration": 0.119872,
     "end_time": "2025-02-20T18:50:28.918718",
     "exception": false,
     "start_time": "2025-02-20T18:50:28.798846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6588596"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = open('/kaggle/input/mark-twain-books/Combine.txt',encoding='utf8',errors='ignore').read()\n",
    "new_str = re.sub('', '', string)\n",
    "open('Train.txt', 'w').write(new_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b75dd0d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:50:28.942165Z",
     "iopub.status.busy": "2025-02-20T18:50:28.941727Z",
     "iopub.status.idle": "2025-02-20T18:50:29.061005Z",
     "shell.execute_reply": "2025-02-20T18:50:29.059727Z"
    },
    "papermill": {
     "duration": 0.132994,
     "end_time": "2025-02-20T18:50:29.062927",
     "exception": false,
     "start_time": "2025-02-20T18:50:28.929933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7db506286dbf41bcb388edc822a90950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_ckpt = \"roberta-base\"\n",
    "config = AutoConfig.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59562261",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:50:29.087291Z",
     "iopub.status.busy": "2025-02-20T18:50:29.086851Z",
     "iopub.status.idle": "2025-02-20T18:50:29.094043Z",
     "shell.execute_reply": "2025-02-20T18:50:29.092795Z"
    },
    "papermill": {
     "duration": 0.021288,
     "end_time": "2025-02-20T18:50:29.095888",
     "exception": false,
     "start_time": "2025-02-20T18:50:29.074600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"_name_or_path\": \"roberta-base\",\n",
       "  \"architectures\": [\n",
       "    \"RobertaForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.47.0\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9ab186b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:50:29.119525Z",
     "iopub.status.busy": "2025-02-20T18:50:29.119157Z",
     "iopub.status.idle": "2025-02-20T18:50:29.123465Z",
     "shell.execute_reply": "2025-02-20T18:50:29.122391Z"
    },
    "papermill": {
     "duration": 0.018223,
     "end_time": "2025-02-20T18:50:29.125411",
     "exception": false,
     "start_time": "2025-02-20T18:50:29.107188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "from collections import namedtuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e95cc4fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:50:29.150658Z",
     "iopub.status.busy": "2025-02-20T18:50:29.150230Z",
     "iopub.status.idle": "2025-02-20T18:50:29.165479Z",
     "shell.execute_reply": "2025-02-20T18:50:29.164017Z"
    },
    "papermill": {
     "duration": 0.030662,
     "end_time": "2025-02-20T18:50:29.167756",
     "exception": false,
     "start_time": "2025-02-20T18:50:29.137094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = SimpleNamespace(**config.__dict__)\n",
    "config.vocab_size = len(tokenizer)\n",
    "config.num_hidden_layers = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0befdb57",
   "metadata": {
    "papermill": {
     "duration": 0.010597,
     "end_time": "2025-02-20T18:50:29.190278",
     "exception": false,
     "start_time": "2025-02-20T18:50:29.179681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61327679",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:50:29.213770Z",
     "iopub.status.busy": "2025-02-20T18:50:29.213418Z",
     "iopub.status.idle": "2025-02-20T18:50:30.509575Z",
     "shell.execute_reply": "2025-02-20T18:50:30.508622Z"
    },
    "papermill": {
     "duration": 1.310515,
     "end_time": "2025-02-20T18:50:30.511551",
     "exception": false,
     "start_time": "2025-02-20T18:50:29.201036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Ignoring sinusoidal or absolute position embeddings because rope,is enable\n"
     ]
    }
   ],
   "source": [
    "model = DecoderModel.from_config(config,pos_embedding_type='rope')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c2db1c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:50:30.535447Z",
     "iopub.status.busy": "2025-02-20T18:50:30.535037Z",
     "iopub.status.idle": "2025-02-20T18:50:30.555096Z",
     "shell.execute_reply": "2025-02-20T18:50:30.554161Z"
    },
    "papermill": {
     "duration": 0.034115,
     "end_time": "2025-02-20T18:50:30.557000",
     "exception": false,
     "start_time": "2025-02-20T18:50:30.522885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.word_embeddings = nn.Embedding.from_pretrained(\n",
    "    state_dict[\"transformer.wte.weight\"], freeze=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8a4b18",
   "metadata": {
    "papermill": {
     "duration": 0.010483,
     "end_time": "2025-02-20T18:50:30.578955",
     "exception": false,
     "start_time": "2025-02-20T18:50:30.568472",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Data Source**\n",
    "\n",
    "https://www.kaggle.com/datasets/msinger007/mark-twain-books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b083b6ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:50:30.602000Z",
     "iopub.status.busy": "2025-02-20T18:50:30.601640Z",
     "iopub.status.idle": "2025-02-20T18:50:30.605805Z",
     "shell.execute_reply": "2025-02-20T18:50:30.604740Z"
    },
    "papermill": {
     "duration": 0.017798,
     "end_time": "2025-02-20T18:50:30.607596",
     "exception": false,
     "start_time": "2025-02-20T18:50:30.589798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = 'Train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e2c1b7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:50:30.630718Z",
     "iopub.status.busy": "2025-02-20T18:50:30.630364Z",
     "iopub.status.idle": "2025-02-20T18:50:30.639610Z",
     "shell.execute_reply": "2025-02-20T18:50:30.638444Z"
    },
    "papermill": {
     "duration": 0.022969,
     "end_time": "2025-02-20T18:50:30.641621",
     "exception": false,
     "start_time": "2025-02-20T18:50:30.618652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer,\n",
    "        file_path: str,\n",
    "        block_size: int):\n",
    "        if os.path.isfile(file_path) is False:\n",
    "            raise ValueError(f\"Input file path {file_path} not found\")\n",
    "\n",
    "        block_size = block_size - tokenizer.num_special_tokens_to_add(pair=False)\n",
    "        saved = False\n",
    "        cache_dir = None\n",
    "        directory, filename = os.path.split(file_path)\n",
    "        cached_features_file = os.path.join(\n",
    "            cache_dir if cache_dir is not None else directory,\n",
    "            f\"cached_lm_{tokenizer.__class__.__name__}_{block_size}_{filename}\",\n",
    "        )\n",
    "\n",
    "     \n",
    "        if os.path.exists(cached_features_file) and saved :\n",
    "                start = time.time()\n",
    "                with open(cached_features_file, \"rb\") as handle:\n",
    "                    self.examples = pickle.load(handle)\n",
    "#                 logger.info(\n",
    "#                     f\"Loading features from cached file {cached_features_file} [took %.3f s]\", time.time() - start\n",
    "#                 )\n",
    "\n",
    "        else:\n",
    "#                 logger.info(f\"Creating features from dataset file at {directory}\")\n",
    "\n",
    "                self.examples = []\n",
    "                with open(file_path, encoding=\"utf-8\") as f:\n",
    "                    text = f.read()\n",
    "\n",
    "                tokenized_text = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text))\n",
    "\n",
    "                for i in range(0, len(tokenized_text) - block_size + 1, block_size):  # Truncate in block of block_size\n",
    "                    self.examples.append(tokenizer.build_inputs_with_special_tokens(tokenized_text[i : i + block_size]))\n",
    "                    # )\n",
    "                # Note that we are losing the last truncated example here for the sake of simplicity (no padding)\n",
    "                # If your dataset is small, first you should look for a bigger one :-) and second you\n",
    "                # can change this behavior by adding (model specific) padding.\n",
    "\n",
    "                start = time.time()\n",
    "                with open(cached_features_file, \"wb\") as handle:\n",
    "                    pickle.dump(self.examples, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                    saved = True\n",
    "#                 logger.info(\n",
    "#                     f\"Saving features into cached file {cached_features_file} [took {time.time() - start:.3f} s]\"\n",
    "#                 )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, i) -> torch.Tensor:\n",
    "        return {\"input_ids\":torch.tensor(self.examples[i], dtype=torch.long)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c9152f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:50:30.664805Z",
     "iopub.status.busy": "2025-02-20T18:50:30.664469Z",
     "iopub.status.idle": "2025-02-20T18:50:30.669623Z",
     "shell.execute_reply": "2025-02-20T18:50:30.668517Z"
    },
    "papermill": {
     "duration": 0.018582,
     "end_time": "2025-02-20T18:50:30.671310",
     "exception": false,
     "start_time": "2025-02-20T18:50:30.652728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    labels = batch[\"input_ids\"].clone()\n",
    "    if tokenizer.pad_token_id is not None:\n",
    "        labels[labels == tokenizer.pad_token_id] = -100\n",
    "    batch[\"labels\"] = labels\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d86147ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:50:30.694665Z",
     "iopub.status.busy": "2025-02-20T18:50:30.694257Z",
     "iopub.status.idle": "2025-02-20T18:50:40.446346Z",
     "shell.execute_reply": "2025-02-20T18:50:40.445058Z"
    },
    "papermill": {
     "duration": 9.766082,
     "end_time": "2025-02-20T18:50:40.448491",
     "exception": false,
     "start_time": "2025-02-20T18:50:30.682409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1580900 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(TextDataset(tokenizer,train_path,128), batch_size=16, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9f623f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:50:40.473887Z",
     "iopub.status.busy": "2025-02-20T18:50:40.473519Z",
     "iopub.status.idle": "2025-02-20T18:50:40.477565Z",
     "shell.execute_reply": "2025-02-20T18:50:40.476398Z"
    },
    "papermill": {
     "duration": 0.018622,
     "end_time": "2025-02-20T18:50:40.479251",
     "exception": false,
     "start_time": "2025-02-20T18:50:40.460629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for data in train_loader:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfa5f00c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:50:40.503541Z",
     "iopub.status.busy": "2025-02-20T18:50:40.503152Z",
     "iopub.status.idle": "2025-02-20T18:50:40.507105Z",
     "shell.execute_reply": "2025-02-20T18:50:40.506199Z"
    },
    "papermill": {
     "duration": 0.017517,
     "end_time": "2025-02-20T18:50:40.508747",
     "exception": false,
     "start_time": "2025-02-20T18:50:40.491230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# out = model(**data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23e526ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:50:40.532621Z",
     "iopub.status.busy": "2025-02-20T18:50:40.532251Z",
     "iopub.status.idle": "2025-02-20T18:50:40.537444Z",
     "shell.execute_reply": "2025-02-20T18:50:40.536503Z"
    },
    "papermill": {
     "duration": 0.01892,
     "end_time": "2025-02-20T18:50:40.539076",
     "exception": false,
     "start_time": "2025-02-20T18:50:40.520156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_fn(labels,prediction_scores):\n",
    "    shifted_prediction_scores = prediction_scores[:, :-1, :].contiguous()\n",
    "    labels = labels[:, 1:].contiguous()\n",
    "    loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-100)\n",
    "    lm_loss = loss_fct(shifted_prediction_scores.view(-1, config.vocab_size), labels.view(-1))\n",
    "    return lm_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b27fbd8",
   "metadata": {
    "papermill": {
     "duration": 0.010808,
     "end_time": "2025-02-20T18:50:40.561461",
     "exception": false,
     "start_time": "2025-02-20T18:50:40.550653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f6a88c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:50:40.585592Z",
     "iopub.status.busy": "2025-02-20T18:50:40.585228Z",
     "iopub.status.idle": "2025-02-20T18:50:40.597484Z",
     "shell.execute_reply": "2025-02-20T18:50:40.596399Z"
    },
    "papermill": {
     "duration": 0.026186,
     "end_time": "2025-02-20T18:50:40.599208",
     "exception": false,
     "start_time": "2025-02-20T18:50:40.573022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(model, train_loader, EPOCHS=3):\n",
    "    EPOCHS = 5\n",
    "    accumulation_steps = 2\n",
    "    lr=5e-5\n",
    "    # train it fully \n",
    "    no_decay = ['bias', 'layerNorm.weight','layerNorm.bias']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=lr)\n",
    "    num_train_optimization_steps = int(EPOCHS * len(train_loader) / accumulation_steps)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0.05 * num_train_optimization_steps,\n",
    "                                        num_training_steps=num_train_optimization_steps)\n",
    "    best_epoch_loss = np.inf\n",
    "    accelerator = Accelerator(log_with=\"tensorboard\",project_dir=\".\",mixed_precision=\"bf16\",gradient_accumulation_steps=2)\n",
    "    Config = {\n",
    "        \"num_epoch\": EPOCHS,\n",
    "        \"learning_rate\": lr,\n",
    "        \"loss_function\": str(torch.nn.CrossEntropyLoss),\n",
    "    }\n",
    "    epoch_check = len(train_loader)\n",
    "    total_step = epoch_check * EPOCHS\n",
    "    accelerator.init_trackers(\"CLM_project\", config=Config)\n",
    "    # train_bar =tqdm(total=total_step, dynamic_ncols=True, disable=not accelerator.is_main_process)\n",
    "    train_loader,model,optimizer,scheduler =  accelerator.prepare(train_loader,model, optimizer,scheduler)\n",
    "    model.train()\n",
    "    t_step = 0\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        loss_list = []\n",
    "        for step, data in enumerate(train_loader):\n",
    "            # train_bar.update(1)\n",
    "            with accelerator.accumulate(model):\n",
    "                data =  collate(data)\n",
    "                x = data[\"input_ids\"] #.to(device)\n",
    "                y = data['labels'] #.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                pred = model(input_ids = x).logits\n",
    "                loss = loss_fn(y,pred)\n",
    "                accelerator.backward(loss)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                accelerator.log({\"training_loss_step\": loss}, step=t_step)\n",
    "                t_step+=1\n",
    "            \n",
    "            loss_list.append(loss.detach().cpu().item())\n",
    "        \n",
    "        avg_loss = np.round(np.mean(loss_list), 4)\n",
    "\n",
    "        accelerator.print(f'Epoch--{epoch+1} ### Train loss---{avg_loss}')\n",
    "        \n",
    "    PATH = f\"decoder__{epoch}.pth\"\n",
    "    model = accelerator.unwrap_model(model)\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "    accelerator.end_training()\n",
    "    accelerator.free_memory(train_loader,model, optimizer,scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3eda29e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:50:40.623320Z",
     "iopub.status.busy": "2025-02-20T18:50:40.622882Z",
     "iopub.status.idle": "2025-02-20T18:50:40.626802Z",
     "shell.execute_reply": "2025-02-20T18:50:40.625857Z"
    },
    "papermill": {
     "duration": 0.017806,
     "end_time": "2025-02-20T18:50:40.628409",
     "exception": false,
     "start_time": "2025-02-20T18:50:40.610603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "160aa956",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:50:40.652220Z",
     "iopub.status.busy": "2025-02-20T18:50:40.651822Z",
     "iopub.status.idle": "2025-02-20T19:08:48.111523Z",
     "shell.execute_reply": "2025-02-20T19:08:48.109956Z"
    },
    "papermill": {
     "duration": 1087.473938,
     "end_time": "2025-02-20T19:08:48.113665",
     "exception": false,
     "start_time": "2025-02-20T18:50:40.639727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 2 GPUs.\n",
      "Epoch--1 ### Train loss---7.7216\n",
      "Epoch--2 ### Train loss---6.034\n",
      "Epoch--3 ### Train loss---5.6727\n",
      "Epoch--4 ### Train loss---5.5007\n",
      "Epoch--5 ### Train loss---5.4067\n"
     ]
    }
   ],
   "source": [
    "from accelerate import notebook_launcher\n",
    "notebook_launcher(train, (model,train_loader), num_processes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8eea9838",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T19:08:48.140762Z",
     "iopub.status.busy": "2025-02-20T19:08:48.140361Z",
     "iopub.status.idle": "2025-02-20T19:08:49.309450Z",
     "shell.execute_reply": "2025-02-20T19:08:49.307790Z"
    },
    "papermill": {
     "duration": 1.185995,
     "end_time": "2025-02-20T19:08:49.311756",
     "exception": false,
     "start_time": "2025-02-20T19:08:48.125761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Ignoring sinusoidal or absolute position embeddings because rope,is enable\n"
     ]
    }
   ],
   "source": [
    "model = DecoderModel.from_config(config,pos_embedding_type='rope')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc3c129e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T19:08:49.338567Z",
     "iopub.status.busy": "2025-02-20T19:08:49.338191Z",
     "iopub.status.idle": "2025-02-20T19:08:50.273850Z",
     "shell.execute_reply": "2025-02-20T19:08:50.272644Z"
    },
    "papermill": {
     "duration": 0.952323,
     "end_time": "2025-02-20T19:08:50.276523",
     "exception": false,
     "start_time": "2025-02-20T19:08:49.324200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('/kaggle/working/decoder__4.pth', weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6615ddff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T19:08:50.307592Z",
     "iopub.status.busy": "2025-02-20T19:08:50.306998Z",
     "iopub.status.idle": "2025-02-20T19:08:50.315854Z",
     "shell.execute_reply": "2025-02-20T19:08:50.311752Z"
    },
    "papermill": {
     "duration": 0.028865,
     "end_time": "2025-02-20T19:08:50.318362",
     "exception": false,
     "start_time": "2025-02-20T19:08:50.289497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cbb33533",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T19:08:50.345000Z",
     "iopub.status.busy": "2025-02-20T19:08:50.344636Z",
     "iopub.status.idle": "2025-02-20T19:08:50.511695Z",
     "shell.execute_reply": "2025-02-20T19:08:50.510304Z"
    },
    "papermill": {
     "duration": 0.182661,
     "end_time": "2025-02-20T19:08:50.513719",
     "exception": false,
     "start_time": "2025-02-20T19:08:50.331058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderModel(\n",
       "  (word_embeddings): Embedding(50257, 768, padding_idx=1)\n",
       "  (all_layer): ModuleList(\n",
       "    (0-5): 6 x DecoderLayer(\n",
       "      (attention): DecoderAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out): AttentionSelfOutput(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (intermediate): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (layerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (act_fn): GELU(approximate='none')\n",
       "        (out): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): LMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=50257, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5091eeba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T19:08:50.539665Z",
     "iopub.status.busy": "2025-02-20T19:08:50.539276Z",
     "iopub.status.idle": "2025-02-20T19:08:50.552076Z",
     "shell.execute_reply": "2025-02-20T19:08:50.550785Z"
    },
    "papermill": {
     "duration": 0.027668,
     "end_time": "2025-02-20T19:08:50.553824",
     "exception": false,
     "start_time": "2025-02-20T19:08:50.526156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate(\n",
    "    model,\n",
    "    input_ids: torch.Tensor,\n",
    "    attention_mask: torch.Tensor,\n",
    "    max_len: int = 20,\n",
    "    temperature: float = 1.0,\n",
    "    use_cache: bool = True,\n",
    "    do_sample: bool = False,\n",
    "    use_static_cache: bool = False,\n",
    ") -> torch.Tensor:\n",
    "\n",
    "    device = input_ids.device\n",
    "\n",
    "    all_prompt_size = [t.size()[0] for t in input_ids]\n",
    "\n",
    "    min_prompt_len = min(all_prompt_size)\n",
    "    max_prompt_len = max(all_prompt_size)\n",
    "\n",
    "    max_len = (\n",
    "        max_len + max_prompt_len\n",
    "    )  # get  max len (prompt + to be generated token combined)\n",
    "\n",
    "    pad_id = getattr(model.config, \"pad_token_id\", 50256)\n",
    "    bsz, _ = input_ids.size()\n",
    "    tokens = torch.full((bsz, max_len), pad_id, dtype=torch.long, device=device)\n",
    "\n",
    "    kv_cache = None\n",
    "    if use_cache:\n",
    "        if use_static_cache:\n",
    "            kv_cache = StaticCache(model.config, max_cache_len=max_len, batch_size=bsz)\n",
    "        else:\n",
    "            kv_cache = DynamicCache(model.config)\n",
    "\n",
    "    for k, t in enumerate(input_ids):\n",
    "        tokens[k, : t.size()[0]] = t\n",
    "\n",
    "    prev_pos = torch.tensor(0, device=device)\n",
    "    eos_reached = torch.tensor([False] * bsz, device=device)\n",
    "    # to break generation if eos reached for all  prompt\n",
    "\n",
    "    input_text_mask = tokens != pad_id  # mask to fill generated values into batch\n",
    "\n",
    "    stop_tokens = torch.tensor(getattr(model.config, \"eos_token_id\", 50256), device=device)\n",
    "    for cur_pos in range(min_prompt_len, max_len):\n",
    "\n",
    "        # Get the model output\n",
    "        with torch.no_grad():\n",
    "            outputs = model(\n",
    "                input_ids=tokens[:, prev_pos:cur_pos],\n",
    "                attention_mask=attention_mask,\n",
    "                use_cache=use_cache,\n",
    "                kv_cache=kv_cache,\n",
    "                start_pos=prev_pos,\n",
    "            )\n",
    "        kv_cache = outputs.kv_cache\n",
    "        next_token_logits = outputs.logits[:, -1] / temperature\n",
    "\n",
    "        if do_sample:\n",
    "            next_token = torch.multinomial(next_token_logits, num_samples=1)\n",
    "        else:\n",
    "            _, next_token = torch.topk(next_token_logits, k=1, dim=-1)\n",
    "\n",
    "        next_token = next_token.reshape(-1)\n",
    "        # only replace token if prompt has already been generated\n",
    "        next_token = torch.where(\n",
    "            input_text_mask[:, cur_pos], tokens[:, cur_pos], next_token\n",
    "        )\n",
    "        tokens[:, cur_pos] = next_token\n",
    "        eos_reached |= (~input_text_mask[:, cur_pos]) & (\n",
    "            torch.isin(next_token, stop_tokens)\n",
    "        )\n",
    "\n",
    "        if use_cache:\n",
    "            prev_pos = cur_pos\n",
    "\n",
    "        attention_mask = torch.cat(\n",
    "            [attention_mask, torch.ones((bsz, 1), device=device)], dim=-1\n",
    "        )\n",
    "        if all(eos_reached):\n",
    "            break\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c53a5f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T19:08:50.581076Z",
     "iopub.status.busy": "2025-02-20T19:08:50.580706Z",
     "iopub.status.idle": "2025-02-20T19:08:50.586886Z",
     "shell.execute_reply": "2025-02-20T19:08:50.585484Z"
    },
    "papermill": {
     "duration": 0.02136,
     "end_time": "2025-02-20T19:08:50.588946",
     "exception": false,
     "start_time": "2025-02-20T19:08:50.567586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = tokenizer([\"this is a test, blue\",\"Well, sir, you could\"], return_tensors=\"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "406d51f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T19:08:50.615993Z",
     "iopub.status.busy": "2025-02-20T19:08:50.615604Z",
     "iopub.status.idle": "2025-02-20T19:08:50.634424Z",
     "shell.execute_reply": "2025-02-20T19:08:50.632939Z"
    },
    "papermill": {
     "duration": 0.034999,
     "end_time": "2025-02-20T19:08:50.636726",
     "exception": false,
     "start_time": "2025-02-20T19:08:50.601727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 5661,   318,   257,  1332,    11,  4171],\n",
       "        [ 5779,    11, 15967,    11,   345,   714]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6da27304",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T19:08:50.765869Z",
     "iopub.status.busy": "2025-02-20T19:08:50.765502Z",
     "iopub.status.idle": "2025-02-20T19:08:50.770939Z",
     "shell.execute_reply": "2025-02-20T19:08:50.769671Z"
    },
    "papermill": {
     "duration": 0.021589,
     "end_time": "2025-02-20T19:08:50.773024",
     "exception": false,
     "start_time": "2025-02-20T19:08:50.751435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_ids , attention_mask = text['input_ids'],text['attention_mask']\n",
    "input_ids = input_ids.to(device)\n",
    "attention_mask = attention_mask.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6384a457",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T19:08:50.798868Z",
     "iopub.status.busy": "2025-02-20T19:08:50.798459Z",
     "iopub.status.idle": "2025-02-20T19:08:51.702442Z",
     "shell.execute_reply": "2025-02-20T19:08:51.701219Z"
    },
    "papermill": {
     "duration": 0.918917,
     "end_time": "2025-02-20T19:08:51.704515",
     "exception": false,
     "start_time": "2025-02-20T19:08:50.785598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this is a test, blue, and the  time, and the time was a little, and the time was a little ',\n",
       " \"Well, sir, you could not  be a good-tm electronic works.  The man's time, I have been a\"]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = generate(model,input_ids=input_ids , attention_mask=attention_mask,use_cache=False)\n",
    "tokenizer.batch_decode(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5adf67",
   "metadata": {
    "papermill": {
     "duration": 0.015388,
     "end_time": "2025-02-20T19:08:51.732477",
     "exception": false,
     "start_time": "2025-02-20T19:08:51.717089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e02088b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T19:08:51.759506Z",
     "iopub.status.busy": "2025-02-20T19:08:51.759068Z",
     "iopub.status.idle": "2025-02-20T19:08:51.984999Z",
     "shell.execute_reply": "2025-02-20T19:08:51.983802Z"
    },
    "papermill": {
     "duration": 0.241639,
     "end_time": "2025-02-20T19:08:51.986857",
     "exception": false,
     "start_time": "2025-02-20T19:08:51.745218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this is a test, blue, and the  time, and the time was a little, and the time was a little ',\n",
       " \"Well, sir, you could not  be a good-tm electronic works.  The man's time, I have been a\"]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = generate(model,input_ids=input_ids , attention_mask=attention_mask,use_cache=True)\n",
    "tokenizer.batch_decode(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4cfc64de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T19:08:52.012816Z",
     "iopub.status.busy": "2025-02-20T19:08:52.012418Z",
     "iopub.status.idle": "2025-02-20T19:08:52.164528Z",
     "shell.execute_reply": "2025-02-20T19:08:52.163403Z"
    },
    "papermill": {
     "duration": 0.167111,
     "end_time": "2025-02-20T19:08:52.166293",
     "exception": false,
     "start_time": "2025-02-20T19:08:51.999182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this is a test, blue, and the  time, and the time was a little, and the time was a little ',\n",
       " \"Well, sir, you could not  be a good-tm electronic works.  The man's time, I have been a\"]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = generate(model,input_ids=input_ids , attention_mask=attention_mask,use_cache=True, use_static_cache=True)\n",
    "tokenizer.batch_decode(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f617b81",
   "metadata": {
    "papermill": {
     "duration": 0.013236,
     "end_time": "2025-02-20T19:08:52.191899",
     "exception": false,
     "start_time": "2025-02-20T19:08:52.178663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 623,
     "sourceId": 1190,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3277362,
     "sourceId": 5699740,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 129796172,
     "sourceType": "kernelVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1169.435122,
   "end_time": "2025-02-20T19:08:55.141315",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-20T18:49:25.706193",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01ce6c1406514f8dbafa90641ed791a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3fab8520cb30405abde5d11cc1115425",
       "placeholder": "",
       "style": "IPY_MODEL_b22e59e6012349b0a579b2c3c996d48b",
       "tabbable": null,
       "tooltip": null,
       "value": "665/665[00:00&lt;00:00,54.8kB/s]"
      }
     },
     "05a5baf67a1c495e98726af9c0fd86d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fe8b56907f8f48ccb0283172b9ffd0f9",
       "placeholder": "",
       "style": "IPY_MODEL_3a985b81119d46d08e7bd15f924ab822",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.json:100%"
      }
     },
     "07e62d96ee364198981d1df2c939f83c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "09ae65f97cf7408d9d3d0b9261834f94": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c94a1384e4414ade8ec854eaeb430d8a",
       "placeholder": "",
       "style": "IPY_MODEL_ad697d3545704641b3be38c7924ae7df",
       "tabbable": null,
       "tooltip": null,
       "value": "merges.txt:100%"
      }
     },
     "135520a7180b4721bb3b1437ce611e5f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "13a3772062454fe19ee16277b5dd7ec0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "22274867aa234551879e8533b3e750fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2b8f414d8d674a7485a8d64016985f30": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2d86fe31033a4f0c85feb802e2ec63f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_73ef694baeee4085b43be195d7e2ecfd",
       "placeholder": "",
       "style": "IPY_MODEL_a28d79aca215484485148bb8ddbdbc85",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer.json:100%"
      }
     },
     "2dcd4900851b40779e6aa0c34c0266a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "301b9f9daa3a4288a4bbe0e139de85b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_71021c275f4a4fecb31aedb3d770d22d",
       "max": 665.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_cb5847d1b46e44a3b785ec6eceb7a602",
       "tabbable": null,
       "tooltip": null,
       "value": 665.0
      }
     },
     "305e4f1e9aa840d6bd75245de58de8b0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "33edbfb8b5d9426aaf9145d3be954a8b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_05a5baf67a1c495e98726af9c0fd86d2",
        "IPY_MODEL_565e972910ae45f5a98afd85763341e3",
        "IPY_MODEL_5b6a633d095e41029db456b6bdbd9c08"
       ],
       "layout": "IPY_MODEL_7214865f69cd49e2b812753f43552a4f",
       "tabbable": null,
       "tooltip": null
      }
     },
     "349a57ef14874c37b3985270844b8931": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "356fe8d190d34fe5a87f069cc618af45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2d86fe31033a4f0c85feb802e2ec63f8",
        "IPY_MODEL_a92dc3d34ce34129a4be9028b2f25d70",
        "IPY_MODEL_8befc78f79d449339d715ffad502a43f"
       ],
       "layout": "IPY_MODEL_e8e26a3afde34c0eb96e8a210ea8d1bf",
       "tabbable": null,
       "tooltip": null
      }
     },
     "394bd1b112784a79bb451076397d2198": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3a985b81119d46d08e7bd15f924ab822": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3ea8f3abab884e8984796105df4b3f74": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3fab8520cb30405abde5d11cc1115425": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "40e6f9fcc6b04fd9855143842b660d7a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_900caa04d9b440e5b688cee4f8f8671e",
       "placeholder": "",
       "style": "IPY_MODEL_2b8f414d8d674a7485a8d64016985f30",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json:100%"
      }
     },
     "4124b319a26d405c902f8084dbcbcddc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b9843099dc314955ad1f8cf1222698bd",
        "IPY_MODEL_301b9f9daa3a4288a4bbe0e139de85b9",
        "IPY_MODEL_01ce6c1406514f8dbafa90641ed791a8"
       ],
       "layout": "IPY_MODEL_49e80ccb5ce141cca029fad8ff05c16b",
       "tabbable": null,
       "tooltip": null
      }
     },
     "49e80ccb5ce141cca029fad8ff05c16b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4f7145176a8043919ec752a135456b54": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "54868254de97442bb071f665dc9cc272": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5587de0117ac46d19e5d09a9b7bb4f5b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "565e972910ae45f5a98afd85763341e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_decf8e24f2914e34a273b3cb416eb0f2",
       "max": 1042301.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9696c1d1f6974c188ba5299a1ff7a2a0",
       "tabbable": null,
       "tooltip": null,
       "value": 1042301.0
      }
     },
     "5b6a633d095e41029db456b6bdbd9c08": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4f7145176a8043919ec752a135456b54",
       "placeholder": "",
       "style": "IPY_MODEL_5b7d733ab77542d79f617b0b2be65684",
       "tabbable": null,
       "tooltip": null,
       "value": "1.04M/1.04M[00:00&lt;00:00,6.95MB/s]"
      }
     },
     "5b7d733ab77542d79f617b0b2be65684": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5ea4ce59053f474aa8f4836dd749d76a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_349a57ef14874c37b3985270844b8931",
       "max": 26.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e58a9231dad547e3a0200150189b2f23",
       "tabbable": null,
       "tooltip": null,
       "value": 26.0
      }
     },
     "61e9416b7e5b4a18bf38adecbdb5ed3b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "63ee632aa8bf41f791f88121353fa736": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "71021c275f4a4fecb31aedb3d770d22d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7214865f69cd49e2b812753f43552a4f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "73ef694baeee4085b43be195d7e2ecfd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "78c6693f89f44dcd89161e51369665ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7db506286dbf41bcb388edc822a90950": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_40e6f9fcc6b04fd9855143842b660d7a",
        "IPY_MODEL_9e3ee993124840dcb8ddc31981520fad",
        "IPY_MODEL_99041188572b415fa48925ef5fab069b"
       ],
       "layout": "IPY_MODEL_b8e0d27ecf01446992530684988b087a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "895c619d7ec746a99c717b6c4ad54714": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b2679867bf0449e49a1023fa884f3c1b",
        "IPY_MODEL_5ea4ce59053f474aa8f4836dd749d76a",
        "IPY_MODEL_edd50441353b4779bb1b1ef942da7079"
       ],
       "layout": "IPY_MODEL_e469a1119a524b349ccddedf3c7ec6b9",
       "tabbable": null,
       "tooltip": null
      }
     },
     "8befc78f79d449339d715ffad502a43f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_acf862b8445e4d79afce884efe38f2e9",
       "placeholder": "",
       "style": "IPY_MODEL_22274867aa234551879e8533b3e750fa",
       "tabbable": null,
       "tooltip": null,
       "value": "1.36M/1.36M[00:00&lt;00:00,25.0MB/s]"
      }
     },
     "900caa04d9b440e5b688cee4f8f8671e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "913d4ed2806543fb828e0be14603d634": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_61e9416b7e5b4a18bf38adecbdb5ed3b",
       "max": 456318.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_63ee632aa8bf41f791f88121353fa736",
       "tabbable": null,
       "tooltip": null,
       "value": 456318.0
      }
     },
     "9378adcf483744458132ee9681d58091": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9696c1d1f6974c188ba5299a1ff7a2a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "99041188572b415fa48925ef5fab069b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_394bd1b112784a79bb451076397d2198",
       "placeholder": "",
       "style": "IPY_MODEL_78c6693f89f44dcd89161e51369665ba",
       "tabbable": null,
       "tooltip": null,
       "value": "481/481[00:00&lt;00:00,37.3kB/s]"
      }
     },
     "99f446da30d8489da77443a382c5753c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9e3ee993124840dcb8ddc31981520fad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3ea8f3abab884e8984796105df4b3f74",
       "max": 481.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a444d5a8e3244d8cb38ca1f6b4304eb4",
       "tabbable": null,
       "tooltip": null,
       "value": 481.0
      }
     },
     "a28d79aca215484485148bb8ddbdbc85": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a444d5a8e3244d8cb38ca1f6b4304eb4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a92dc3d34ce34129a4be9028b2f25d70": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e8170ad1f7b04e868624d126a16f2e24",
       "max": 1355256.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_54868254de97442bb071f665dc9cc272",
       "tabbable": null,
       "tooltip": null,
       "value": 1355256.0
      }
     },
     "aac1ed4ec37440e48b4010bbdeeb523c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_09ae65f97cf7408d9d3d0b9261834f94",
        "IPY_MODEL_913d4ed2806543fb828e0be14603d634",
        "IPY_MODEL_de6e6654d1ab427e8a596da5f9402a46"
       ],
       "layout": "IPY_MODEL_305e4f1e9aa840d6bd75245de58de8b0",
       "tabbable": null,
       "tooltip": null
      }
     },
     "acf862b8445e4d79afce884efe38f2e9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ad697d3545704641b3be38c7924ae7df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b22e59e6012349b0a579b2c3c996d48b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b2679867bf0449e49a1023fa884f3c1b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_07e62d96ee364198981d1df2c939f83c",
       "placeholder": "",
       "style": "IPY_MODEL_f228a9ef44674c2e932084ece1a832d1",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json:100%"
      }
     },
     "b8e0d27ecf01446992530684988b087a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b9843099dc314955ad1f8cf1222698bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_13a3772062454fe19ee16277b5dd7ec0",
       "placeholder": "",
       "style": "IPY_MODEL_9378adcf483744458132ee9681d58091",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json:100%"
      }
     },
     "c94a1384e4414ade8ec854eaeb430d8a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cb5847d1b46e44a3b785ec6eceb7a602": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "de6e6654d1ab427e8a596da5f9402a46": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5587de0117ac46d19e5d09a9b7bb4f5b",
       "placeholder": "",
       "style": "IPY_MODEL_99f446da30d8489da77443a382c5753c",
       "tabbable": null,
       "tooltip": null,
       "value": "456k/456k[00:00&lt;00:00,22.7MB/s]"
      }
     },
     "decf8e24f2914e34a273b3cb416eb0f2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e469a1119a524b349ccddedf3c7ec6b9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e58a9231dad547e3a0200150189b2f23": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e8170ad1f7b04e868624d126a16f2e24": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e8e26a3afde34c0eb96e8a210ea8d1bf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "edd50441353b4779bb1b1ef942da7079": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_135520a7180b4721bb3b1437ce611e5f",
       "placeholder": "",
       "style": "IPY_MODEL_2dcd4900851b40779e6aa0c34c0266a3",
       "tabbable": null,
       "tooltip": null,
       "value": "26.0/26.0[00:00&lt;00:00,1.90kB/s]"
      }
     },
     "f228a9ef44674c2e932084ece1a832d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fe8b56907f8f48ccb0283172b9ffd0f9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
