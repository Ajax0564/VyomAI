{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35ed955d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T13:39:49.673404Z",
     "iopub.status.busy": "2025-06-08T13:39:49.673082Z",
     "iopub.status.idle": "2025-06-08T13:39:55.647067Z",
     "shell.execute_reply": "2025-06-08T13:39:55.646050Z"
    },
    "papermill": {
     "duration": 5.98145,
     "end_time": "2025-06-08T13:39:55.648899",
     "exception": false,
     "start_time": "2025-06-08T13:39:49.667449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "from typing import Callable, Dict, List, Optional, Sequence, Tuple, Union\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, Subset, random_split\n",
    "import numpy as np\n",
    "\n",
    "class BaseDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        images: Union[Sequence, torch.Tensor],\n",
    "        targets: Union[Sequence, torch.Tensor],\n",
    "        transform: Optional[Callable] = None,\n",
    "        target_transform: Optional[Callable] = None,\n",
    "    ) -> None:\n",
    "        self.images = images\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Returns the number of samples.\"\"\"\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        \"\"\"Returns a sample from the dataset.\"\"\"\n",
    "        image, target = self.images[idx], self.targets[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            target = self.target_transform(target)\n",
    "        return image, target\n",
    "\n",
    "\n",
    "class DatasetGenerator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        single_digit_mnist: Dataset,\n",
    "        max_length: int,\n",
    "        min_overlap: float,\n",
    "        max_overlap: float,\n",
    "        padding_index: int,\n",
    "    ) -> None:\n",
    "        self.single_digit_mnist = single_digit_mnist\n",
    "        self.max_length = max_length\n",
    "        self.min_overlap = min_overlap\n",
    "        self.max_overlap = max_overlap\n",
    "        self.padding_index = padding_index\n",
    "\n",
    "        self.mnist_digit_dim = 28\n",
    "        self.samples_by_digit = self._get_samples_by_digit()\n",
    "\n",
    "    def _get_samples_by_digit(self) -> Dict[int, List]:\n",
    "        \"\"\"Stores a collection of images for each digit.\"\"\"\n",
    "        samples_by_digit = defaultdict(list)\n",
    "        for image, digit in self.single_digit_mnist:\n",
    "            samples_by_digit[digit].append(image.squeeze())\n",
    "        blank_image = torch.zeros((self.mnist_digit_dim, self.mnist_digit_dim))\n",
    "        samples_by_digit[-1].append(blank_image)\n",
    "        return samples_by_digit\n",
    "\n",
    "    def generate(self, num_samples) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Main methods to generate a dataset.\n",
    "\n",
    "        Args:\n",
    "            num_samples: Number of samples to generate.\n",
    "\n",
    "        Returns:\n",
    "            Images and labels (padded).\n",
    "        \"\"\"\n",
    "        labels = torch.full((num_samples, self.max_length), self.padding_index)\n",
    "        images = torch.zeros((num_samples, 96, self.mnist_digit_dim * self.max_length))\n",
    "        for i in range(num_samples):\n",
    "            rand_num = self._get_random_number()\n",
    "            for j, digit in enumerate(str(rand_num)):\n",
    "                labels[i, j] = int(digit)\n",
    "            images[i] = self._construct_image_from_number(rand_num)\n",
    "        return images, labels\n",
    "\n",
    "    def _get_random_number(self) -> int:\n",
    "        \"\"\"Generate a random number.\n",
    "\n",
    "        The probabiltiy of getting a small number is artifically inflated; otherwise,\n",
    "        there will be not enough numbers of short lengths and the model will not\n",
    "        generalize well.\n",
    "        \"\"\"\n",
    "        num_digits_choices = list(range(4, self.max_length + 1))\n",
    "        probs = [n / sum(num_digits_choices) for n in num_digits_choices]\n",
    "        num_digits = random.choices(num_digits_choices, weights=probs)[0]\n",
    "        rand_num = random.randint(\n",
    "            int(\"1\" + \"0\" * (num_digits - 1)), int(\"1\" + \"0\" * num_digits) - 1\n",
    "        )\n",
    "        return rand_num\n",
    "\n",
    "    def _construct_image_from_number(self, number: int) -> torch.Tensor:\n",
    "        \"\"\"Concatenate images of single digits.\"\"\"\n",
    "        overlap = random.uniform(self.min_overlap, self.max_overlap)\n",
    "        overlap_width = int(overlap * self.mnist_digit_dim)\n",
    "        width_increment = self.mnist_digit_dim - overlap_width\n",
    "        x, y = 0, 2  # Current pointers at x and y coordinates\n",
    "        digits = self._add_left_and_right_paddings(number)\n",
    "        multi_digit_image = torch.zeros((96, self.mnist_digit_dim * self.max_length))\n",
    "        for digit in digits:\n",
    "            digit_image = random.choice(self.samples_by_digit[digit])\n",
    "            digit_image = torch.clone(\n",
    "                digit_image\n",
    "            )  # To avoid overwriting the original image\n",
    "            digit_image[:, :overlap_width] = torch.maximum(\n",
    "                multi_digit_image[y : y + self.mnist_digit_dim, x : x + overlap_width],\n",
    "                digit_image[:, :overlap_width],\n",
    "            )\n",
    "            multi_digit_image[\n",
    "                y : y + self.mnist_digit_dim, x : x + self.mnist_digit_dim\n",
    "            ] = digit_image\n",
    "            x += width_increment\n",
    "        return multi_digit_image\n",
    "\n",
    "    def _add_left_and_right_paddings(self, number: int) -> List[int]:\n",
    "        \"\"\"Add paddings to left and right of the number.\"\"\"\n",
    "        digits = [int(digit) for digit in list(str(number))]\n",
    "        remanining_length = self.max_length - len(digits)\n",
    "        left_padding = random.randint(0, remanining_length)\n",
    "        right_padding = remanining_length - left_padding\n",
    "        digits = [-1] * left_padding + digits + [-1] * right_padding\n",
    "        return digits\n",
    "\n",
    "\n",
    "def split_dataset(dataset: Dataset, fraction: float, seed: int) -> List[Subset]:\n",
    "    \"\"\"Split a dataset into two.\"\"\"\n",
    "    num_samples = len(dataset)\n",
    "    split_a_size = int(num_samples * fraction)\n",
    "    split_b_size = num_samples - split_a_size\n",
    "    return random_split(\n",
    "        dataset,\n",
    "        [split_a_size, split_b_size],\n",
    "        generator=torch.Generator().manual_seed(seed),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b603bf85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T13:39:55.658504Z",
     "iopub.status.busy": "2025-06-08T13:39:55.658076Z",
     "iopub.status.idle": "2025-06-08T13:40:14.224673Z",
     "shell.execute_reply": "2025-06-08T13:40:14.223487Z"
    },
    "papermill": {
     "duration": 18.573637,
     "end_time": "2025-06-08T13:40:14.226672",
     "exception": false,
     "start_time": "2025-06-08T13:39:55.653035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Dict, Optional, Union\n",
    "\n",
    "from pytorch_lightning import LightningDataModule\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "\n",
    "\n",
    "class BaseDataModule(LightningDataModule):\n",
    "    \"\"\"Base data module.\n",
    "\n",
    "    Args:\n",
    "        batch_size: The number samples to load per batch.\n",
    "        num_workers: The number of subprocesses to use for data loading.\n",
    "        pin_memory: Whether to copy Tensors into CUDA pinned memory before returning\n",
    "            them.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, batch_size: int = 32, num_workers: int = 0, pin_memory: bool = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.pin_memory = pin_memory\n",
    "\n",
    "        self.dataset: Dict[str, Union[Dataset, Subset]] = {}\n",
    "\n",
    "    @classmethod\n",
    "    def data_dirname(cls):\n",
    "        \"\"\"Root directory to all datasets.\"\"\"\n",
    "        return os.getcwd()\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"Download and preprocess datasets.\"\"\"\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        \"\"\"Should popularize self.dataset after being called.\"\"\"\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.dataset[\"train\"],\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=self.pin_memory,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.dataset[\"val\"],\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=self.pin_memory,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.dataset[\"test\"],\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=self.pin_memory,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75118b62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T13:40:14.235298Z",
     "iopub.status.busy": "2025-06-08T13:40:14.234002Z",
     "iopub.status.idle": "2025-06-08T13:40:14.242321Z",
     "shell.execute_reply": "2025-06-08T13:40:14.241368Z"
    },
    "papermill": {
     "duration": 0.013931,
     "end_time": "2025-06-08T13:40:14.243922",
     "exception": false,
     "start_time": "2025-06-08T13:40:14.229991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "\n",
    "\n",
    "TRAIN_FRACTION = 0.8\n",
    "\n",
    "\n",
    "class SingleDigitMNIST(BaseDataModule):\n",
    "    \"\"\"Data module for the standard single digit MNIST dataset.\n",
    "\n",
    "    Args:\n",
    "        kwargs: Keyword arguments to BaseDataModule.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.transform = transforms.ToTensor()\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        \"\"\"Download the MNIST dataset.\"\"\"\n",
    "        MNIST(self.data_dirname(), train=True, download=True)\n",
    "        MNIST(self.data_dirname(), train=False, download=True)\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None) -> None:\n",
    "        if stage in (\"fit\", None):\n",
    "            full_dataset = MNIST(\n",
    "                self.data_dirname(), train=True, transform=self.transform\n",
    "            )\n",
    "            self.dataset[\"train\"], self.dataset[\"val\"] = split_dataset(\n",
    "                full_dataset, TRAIN_FRACTION, seed=42\n",
    "            )\n",
    "\n",
    "        if stage in (\"test\", None):\n",
    "            self.dataset[\"test\"] = MNIST(\n",
    "                self.data_dirname(), train=False, transform=self.transform\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "017a7e27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T13:40:14.252927Z",
     "iopub.status.busy": "2025-06-08T13:40:14.252571Z",
     "iopub.status.idle": "2025-06-08T13:40:14.501668Z",
     "shell.execute_reply": "2025-06-08T13:40:14.500362Z"
    },
    "papermill": {
     "duration": 0.25599,
     "end_time": "2025-06-08T13:40:14.503469",
     "exception": false,
     "start_time": "2025-06-08T13:40:14.247479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import h5py\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "\n",
    "class MultiDigitMNIST(BaseDataModule):\n",
    "    \"\"\"Data module for a synthetic multi-digit MNIST dataset.\n",
    "\n",
    "    Args:\n",
    "        num_train: Number of training samples.\n",
    "        num_val: Number of validation samples.\n",
    "        num_test: Number of test samples.\n",
    "        max_length: Maximum number of digits.\n",
    "        min_overlap: Minimum proportion of an image being overlapped with another image.\n",
    "        max_overlap: Maximum proportion of an image being overlapped with another image.\n",
    "        kwargs: Keyward arguments to BaseDataModule.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_train: int = 75000,\n",
    "        num_val: int = 10000,\n",
    "        num_test: int = 20000,\n",
    "        max_length: int = 16,\n",
    "        min_overlap: float = 0.02,\n",
    "        max_overlap: float = 0.5,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        assert 1 <= max_length\n",
    "        assert 0 <= min_overlap < max_overlap\n",
    "\n",
    "        self.num_samples = {\"train\": num_train, \"val\": num_val, \"test\": num_test}\n",
    "        self.max_length = max_length\n",
    "        self.min_overlap = min_overlap\n",
    "        self.max_overlap = max_overlap\n",
    "\n",
    "        self.padding_index = -1\n",
    "        self.blank_index = -1\n",
    "        self.single_digit_mnist = SingleDigitMNIST()\n",
    "        self.transform = {\n",
    "            \"train\": transforms.Compose(\n",
    "                [\n",
    "                    transforms.RandomAffine(\n",
    "                        degrees=(-0.05, 0.05),\n",
    "                        scale=(0.7, 1.1),\n",
    "                        shear=(-30, 30),\n",
    "                        interpolation=InterpolationMode.BILINEAR,\n",
    "                        fill=0,\n",
    "                    ),\n",
    "                    transforms.ToTensor(),\n",
    "                ]\n",
    "            ),\n",
    "            \"val/test\": transforms.ToTensor(),\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def dataset_dirname(self) -> Path:\n",
    "        \"\"\"Directory to the dataset.\"\"\"\n",
    "        return self.data_dirname() \n",
    "\n",
    "    \n",
    "    def dataset_filename(self,indicator = 'b1') -> Path:\n",
    "        \"\"\"Filename of the dataset created by prepare_data.\"\"\"\n",
    "        return (\n",
    "            f\"ml_{self.max_length}_o{self.min_overlap:.2f}_{self.max_overlap:.2f}_\"\n",
    "            f\"ntr{self.num_samples['train']}_nv{self.num_samples['val']}_\"\n",
    "            f\"nte{self.num_samples['test']}_{indicator}.h5\"\n",
    "        )\n",
    "\n",
    "    def prepare_data(self,indicator = 'b1') -> None:\n",
    "        \"\"\"Create a synthetic dataset.\"\"\"\n",
    "        # if self.dataset_filename.is_file():\n",
    "        #     return\n",
    "        self.single_digit_mnist.prepare_data()\n",
    "        self.single_digit_mnist.setup()\n",
    "        # self.dataset_dirname.mkdir(parents=True, exist_ok=True)\n",
    "        with h5py.File(f\"{self.dataset_filename(indicator)}\", \"w\") as f:\n",
    "            for split in (\"train\", \"val\", \"test\"):\n",
    "                print(f\"Preparing {split} dataset...\")\n",
    "                image_generator = DatasetGenerator(\n",
    "                    self.single_digit_mnist.dataset[split],\n",
    "                    max_length=self.max_length,\n",
    "                    min_overlap=self.min_overlap,\n",
    "                    max_overlap=self.max_overlap,\n",
    "                    padding_index=self.padding_index,\n",
    "                )\n",
    "                images, labels = image_generator.generate(self.num_samples[split])\n",
    "                f.create_dataset(\n",
    "                    f\"X_{split}\", data=images, dtype=\"f4\", compression=\"lzf\"\n",
    "                )\n",
    "                f.create_dataset(\n",
    "                    f\"y_{split}\", data=labels, dtype=\"i1\", compression=\"lzf\"\n",
    "                )\n",
    "        print(f\"Dataset saved to {str(self.dataset_filename)}\")\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None) -> None:\n",
    "        if stage in (\"fit\", None):\n",
    "            with h5py.File(self.dataset_filename, \"r\") as f:\n",
    "                X_train = [Image.fromarray(_) for _ in f[\"X_train\"][:]]\n",
    "                y_train = torch.IntTensor(f[\"y_train\"])\n",
    "                X_val = [Image.fromarray(_) for _ in f[\"X_val\"][:]]\n",
    "                y_val = torch.IntTensor(f[\"y_val\"])\n",
    "            self.dataset[\"train\"] = BaseDataset(\n",
    "                X_train, y_train, transform=self.transform[\"train\"]\n",
    "            )\n",
    "            self.dataset[\"val\"] = BaseDataset(\n",
    "                X_val, y_val, transform=self.transform[\"val/test\"]\n",
    "            )\n",
    "\n",
    "        if stage in (\"test\", None):\n",
    "            with h5py.File(self.dataset_filename, \"r\") as f:\n",
    "                X_test = f[\"X_test\"][:]\n",
    "                y_test = torch.IntTensor(f[\"y_test\"][:])\n",
    "            self.dataset[\"test\"] = BaseDataset(\n",
    "                X_test, y_test, transform=self.transform[\"val/test\"]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e38149d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T13:40:14.511300Z",
     "iopub.status.busy": "2025-06-08T13:40:14.510784Z",
     "iopub.status.idle": "2025-06-08T13:40:14.516093Z",
     "shell.execute_reply": "2025-06-08T13:40:14.515297Z"
    },
    "papermill": {
     "duration": 0.010948,
     "end_time": "2025-06-08T13:40:14.517599",
     "exception": false,
     "start_time": "2025-06-08T13:40:14.506651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b842dded",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T13:40:14.525287Z",
     "iopub.status.busy": "2025-06-08T13:40:14.524888Z",
     "iopub.status.idle": "2025-06-08T13:40:14.537712Z",
     "shell.execute_reply": "2025-06-08T13:40:14.536498Z"
    },
    "papermill": {
     "duration": 0.018446,
     "end_time": "2025-06-08T13:40:14.539296",
     "exception": false,
     "start_time": "2025-06-08T13:40:14.520850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 42\n"
     ]
    }
   ],
   "source": [
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5055e0aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T13:40:14.547748Z",
     "iopub.status.busy": "2025-06-08T13:40:14.546909Z",
     "iopub.status.idle": "2025-06-08T13:40:14.552060Z",
     "shell.execute_reply": "2025-06-08T13:40:14.551042Z"
    },
    "papermill": {
     "duration": 0.011047,
     "end_time": "2025-06-08T13:40:14.553802",
     "exception": false,
     "start_time": "2025-06-08T13:40:14.542755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = MultiDigitMNIST()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e066c9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T13:40:14.561475Z",
     "iopub.status.busy": "2025-06-08T13:40:14.561148Z",
     "iopub.status.idle": "2025-06-08T13:43:40.117501Z",
     "shell.execute_reply": "2025-06-08T13:43:40.116480Z"
    },
    "papermill": {
     "duration": 205.562302,
     "end_time": "2025-06-08T13:43:40.119370",
     "exception": false,
     "start_time": "2025-06-08T13:40:14.557068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 11.6MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 338kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.18MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.82MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing train dataset...\n",
      "Preparing val dataset...\n",
      "Preparing test dataset...\n",
      "Dataset saved to <bound method MultiDigitMNIST.dataset_filename of <__main__.MultiDigitMNIST object at 0x7eee8818c850>>\n"
     ]
    }
   ],
   "source": [
    "datamodule = MultiDigitMNIST()\n",
    "datamodule.prepare_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b34b891",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T13:43:40.130454Z",
     "iopub.status.busy": "2025-06-08T13:43:40.129826Z",
     "iopub.status.idle": "2025-06-08T13:43:40.135283Z",
     "shell.execute_reply": "2025-06-08T13:43:40.134346Z"
    },
    "papermill": {
     "duration": 0.012456,
     "end_time": "2025-06-08T13:43:40.136635",
     "exception": false,
     "start_time": "2025-06-08T13:43:40.124179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 2025) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2efe67a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T13:43:40.147065Z",
     "iopub.status.busy": "2025-06-08T13:43:40.146734Z",
     "iopub.status.idle": "2025-06-08T13:43:40.153597Z",
     "shell.execute_reply": "2025-06-08T13:43:40.152467Z"
    },
    "papermill": {
     "duration": 0.014081,
     "end_time": "2025-06-08T13:43:40.155131",
     "exception": false,
     "start_time": "2025-06-08T13:43:40.141050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 2025\n"
     ]
    }
   ],
   "source": [
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f6ea7f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T13:43:40.166232Z",
     "iopub.status.busy": "2025-06-08T13:43:40.165690Z",
     "iopub.status.idle": "2025-06-08T13:43:40.173071Z",
     "shell.execute_reply": "2025-06-08T13:43:40.171404Z"
    },
    "papermill": {
     "duration": 0.015872,
     "end_time": "2025-06-08T13:43:40.175608",
     "exception": false,
     "start_time": "2025-06-08T13:43:40.159736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = MultiDigitMNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eafd516b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T13:43:40.187251Z",
     "iopub.status.busy": "2025-06-08T13:43:40.186690Z",
     "iopub.status.idle": "2025-06-08T13:47:00.424063Z",
     "shell.execute_reply": "2025-06-08T13:47:00.422907Z"
    },
    "papermill": {
     "duration": 200.24813,
     "end_time": "2025-06-08T13:47:00.428861",
     "exception": false,
     "start_time": "2025-06-08T13:43:40.180731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing train dataset...\n",
      "Preparing val dataset...\n",
      "Preparing test dataset...\n",
      "Dataset saved to <bound method MultiDigitMNIST.dataset_filename of <__main__.MultiDigitMNIST object at 0x7eee88169250>>\n"
     ]
    }
   ],
   "source": [
    "datamodule = MultiDigitMNIST()\n",
    "datamodule.prepare_data(indicator='b2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c320c5",
   "metadata": {
    "papermill": {
     "duration": 0.004444,
     "end_time": "2025-06-08T13:47:00.438072",
     "exception": false,
     "start_time": "2025-06-08T13:47:00.433628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 439.672877,
   "end_time": "2025-06-08T13:47:03.893877",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-08T13:39:44.221000",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
